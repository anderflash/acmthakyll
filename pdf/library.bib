@article{Ambrosini2011,
abstract = {When observing someone else acting on an object, people implement goal-specific eye movement programs that are driven by their own motor representation of the observed action. Usually, however, we observe people acting in contexts where more objects, different in shape and size, are present. Is our brain able to select the intended target even when there are different objects in the visual scene? And if this is the case, what kind of information does our motor system capitalize on? We recorded eye movements while participants observed an actor reaching for and grasping one of two objects requiring two different kinds of grip to be picked up. In a control condition, the actor merely reached for and touched one of the two objects without preshaping her hand according to the target features. Results showed higher accuracy and earlier saccadic movements when participants observed an actually grasping hand than when they observed a mere reaching hand devoid of any kind of target-related preshaping. This clearly suggests that the hand preshaping provided the observer with enough motor cues to proactively and reliably saccade toward the object to be grasped, thus identifying it even when the action target was not previously known. Our findings strongly corroborate the direct matching hypothesis suggesting that in processing others' actions, we take advantage of the same motor knowledge that enables us to efficiently perform those actions.},
annote = {- cited by: 18
- kw: identification I-VT eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Ambrosini, E},
doi = {10.​1152/​jn.​00118.​2011},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of neurophysiology/2011/Ambrosini/Ambrosini - 2011 - Grasping with the eyes.pdf:pdf},
journal = {Journal of neurophysiology},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
number = {3},
pages = {1437--1442},
title = {{Grasping with the eyes}},
url = {http://jn.physiology.org/content/106/3/1437.short},
volume = {106},
year = {2011}
}
@inproceedings{Bednarik2005,
abstract = {Eye-movement tracking proved its potentials in many areas of human-computer interaction. Resting on a hypothesis that eye-direction and mind are linked, some of the HCI researchers have employed eye-movement trackers to investigate the visual attention focus of the participants completing their tasks. Others have used the eye-movement tracking in real-time applications, either as a direct interaction device or as an input to gaze-aware interfaces. Inspired by the previous HCI applications, we propose to utilize eye- movement trackers in adaptive systems research and development in two ways. First, the evaluations of adaptive systems could get an access to the information otherwise unavailable, as for instance to how the visual attention and cognitive processing are influenced by an adaptivity implemented into the evaluated system. Second, we propose to employ the eye-movement tracking technologies for a real-time registration of users’ loci of visual attention, therefore increasing the awareness of the adaptive systems about their current users. We discuss possible potentials, difficulties and pitfalls of eye-movement tracking when applied to adaptive systems. We argue that a methodological framework of applying eye-tracking into adaptive systems shall be developed.},
address = {Edinburgh, UK},
annote = {- cited by: 9
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Bednarik, Roman},
booktitle = {Proceedings of the Fourth Workshop on the Evaluation of Adaptive Systems},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Fourth Workshop on the Evaluation of Adaptive Systems/2005/Bednarik/Bednarik - 2005 - Potentials of eye-movement tracking in adaptive systems.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1--8},
title = {{Potentials of eye-movement tracking in adaptive systems}},
url = {http://www.cs.joensuu.fi/pages/int/pub/bednarik05a.pdf},
year = {2005}
}
@incollection{Bednarik2013,
abstract = {Inference about high-level cognitive states during interaction is a fundamental task in building proactive intelligent systems that would allow effective offloading of mental operations to a computational architecture. We introduce an improved machine-learning pipeline able to predict user interactive behavior and performance using real-time eye-tracking. The inference is carried out using a support-vector machine (SVM) on a large set of features computed from eye movement data that are linked to concurrent high-level behavioral codes based on think aloud protocols. The differences between cognitive states can be inferred from overt visual attention patterns with accuracy over chance levels, although the overall accuracy is still low. The system can also classify and predict performance of the problem-solving users with up to 79 \% accuracy. We suggest this prediction model as a universal approach for understanding of gaze in complex strategic behavior. The findings confirm that eye movement data carry important information about problem solving processes and that proactive systems can benefit from real-time monitoring of visual attention.},
address = {London},
author = {Bednarik, Roman and Eivazi, S and Vrzakova, H},
booktitle = {Eye Gaze in Intelligent User Interfaces},
chapter = {7},
doi = {10.1007/978-1-4471-4784-8\_7},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Eye Gaze in Intelligent User Interfaces/2013/Bednarik, Eivazi, Vrzakova/Bednarik, Eivazi, Vrzakova - 2013 - A Computational Approach for Prediction of Problem-Solving Behavior Using Support Vector Machines an.pdf:pdf},
isbn = {978-1-4471-4784-8},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {111--134},
publisher = {Springer London},
title = {{A Computational Approach for Prediction of Problem-Solving Behavior Using Support Vector Machines and Eye-Tracking Data}},
url = {http://link.springer.com/chapter/10.1007/978-1-4471-4784-8\_7},
year = {2013}
}
@article{Behrens2010,
abstract = {This analysis of time series of eye movements is a saccade-detection algorithm that is based on an earlier algorithm. It achieves substantial improvements by using an adaptive-threshold model instead of fixed thresholds and using the eye-movement acceleration signal. This has four advantages: (1) Adaptive thresholds are calculated automatically from the preceding acceleration data for detecting the beginning of a saccade, and thresholds are modified during the saccade. (2) The monotonicity of the position signal during the saccade, together with the acceleration with respect to the thresholds, is used to reliably determine the end of the saccade. (3) This allows differentiation between saccades following the main-sequence and non-main-sequence saccades. (4) Artifacts of various kinds can be detected and eliminated. The algorithm is demonstrated by applying it to human eye movement data (obtained by EOG) recorded during driving a car. A second demonstration of the algorithm detects microsleep episodes in eye movement data.},
annote = {- keyword coletado
        
Resumo: Detec\c{c}\~{a}o de sacadas com limiar adaptativo (usando acelera\c{c}\~{a}o)
O autor defende que o algoritmo cont\'{e}m 4 vantagens:
- 
        
        
Como \'{e} o m\'{e}todo:
- O m\'{e}todo cont\'{e}m como entrada a janela (T) de amostras para calcular o desvio padr\~{a}o do ru\'{\i}do (Sigma), e um valor de multiplicidade (N). Ele usou N=3.4, mas n\~{a}o justificou e n\~{a}o testou esta constante em outros experimentos.
Define uma janela de T amostras para calcular o Sigma. Define o limiar como sendo N*Sigma. Se a acelera\c{c}\~{a}o ultrapassar o limiar, o limiar \'{e} mantido constante por 200ms e em seguida cresce linearmente at\'{e} atingir N*Sigma, onde o limiar \'{e} novamente N*Sigma.
Cria-se uma fun\c{c}\~{a}o = +1 durante a sacada (ultrapassando o limiar),= -1 se ultrapassar o limiar negativo e = 0 quando n\~{a}o detectar sacada (vari\'{a}vel de estado)
O limiar adaptativo detecta outros tipos de movimento sac\'{a}dico, como glissadas.},
author = {Behrens, F and Mackeben, M and Schr\"{o}der-Preikschat, W},
doi = {10.3758/BRM.42.3.701},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2010/Behrens, Mackeben, Schr\"{o}der-Preikschat/Behrens, Mackeben, Schr\"{o}der-Preikschat - 2010 - An improved algorithm for automatic detection of saccades in eye movement data and for.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adaptation,Algorithms,Automation,Automobile Driving,Automobile Driving: psychology,Calibration,Data Collection,Data Collection: methods,Data Interpretation,Electrooculography,Eye Tracking,Fixation,Humans,Ocular,Physiological,Physiological: physiology,Saccades,Saccades: physiology,Segmentation,Sleep,Sleep: physiology,Statistical},
mendeley-tags = {Eye Tracking,Segmentation},
month = aug,
number = {3},
pages = {701--8},
pmid = {20805592},
title = {{An improved algorithm for automatic detection of saccades in eye movement data and for calculating saccade parameters.}},
url = {http://link.springer.com/article/10.3758/BRM.42.3.701 http://www.ncbi.nlm.nih.gov/pubmed/20805592},
volume = {42},
year = {2010}
}
@article{Behrens1992,
abstract = {An algorithm is described to discriminate automatically between saccades and slow eye movements. Sampled data of the eye position have been used to calculate the momentary acceleration of the eye. The higher acceleration values of the saccadic eye movements as opposed to the slow compensatory or pursuit eye movements served to differentiate between the two. The method is demonstrated by search-coil data in squirrel monkeys.},
author = {Behrens, F and Weiss, LR},
doi = {10.1016/0042-6989(92)90031-D},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/1992/Behrens, Weiss/Behrens, Weiss - 1992 - An algorithm separating saccadic from nonsaccadic eye movements automatically by use of the acceleration sign(2).pdf:pdf},
issn = {00426989},
journal = {Vision Research},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = may,
number = {5},
pages = {889--893},
title = {{An algorithm separating saccadic from nonsaccadic eye movements automatically by use of the acceleration signal}},
url = {http://www.sciencedirect.com/science/article/pii/004269899290031D http://linkinghub.elsevier.com/retrieve/pii/004269899290031D},
volume = {32},
year = {1992}
}
@article{Blignaut2009,
abstract = {It is hypothesized that the number, position, size, and duration of fixations are functions of the metric used for dispersion in a dispersion-based fixation detection algorithm, as well as of the threshold value. The sensitivity of the I-DT algorithm for the various independent variables was determined through the analysis of gaze data from chess players during a memory recall experiment. A procedure was followed in which scan paths were generated at distinct intervals in a range of threshold values for each of five different metrics of dispersion. The percentage of points of regard (PORs) used, the number of fixations returned, the spatial dispersion of PORs within fixations, and the difference between the scan paths were used as indicators to determine an optimum threshold value. It was found that a fixation radius of 1 degrees provides a threshold that will ensure replicable results in terms of the number and position of fixations while utilizing about 90\% of the gaze data captured.},
annote = {- keyword coletado
- cited by: 24- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Blignaut, Pieter},
doi = {10.3758/APP.71.4.881},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Attention, perception \& psychophysics/2009/Blignaut/Blignaut - 2009 - Fixation identification the optimum threshold for a dispersion algorithm.pdf:pdf},
issn = {1943-3921},
journal = {Attention, perception \& psychophysics},
keywords = {Adolescent,Adult,Algorithms,Attention,Computer Graphics,Discrimination (Psychology),Eye Tracking,Female,Fixation,Humans,Male,Memory,Middle Aged,Ocular,Orientation,Pattern Recognition,Psychomotor Performance,Psychophysics,Reaction Time,Saccades,Segmentation,Sensory Thresholds,Short-Term,Visual,Young Adult},
mendeley-tags = {Eye Tracking,Segmentation},
month = may,
number = {4},
pages = {881--95},
pmid = {19429966},
title = {{Fixation identification: the optimum threshold for a dispersion algorithm.}},
url = {http://link.springer.com/article/10.3758/APP.71.4.881 http://www.ncbi.nlm.nih.gov/pubmed/19429966},
volume = {71},
year = {2009}
}
@article{Cesarelli2000,
abstract = {Visual acuity in congenital nystagmus has proven to be primarily related to the duration of foveation periods, during which the image of a target falls onto the fovea and eye velocity slows down. It was found that the longer the foveation time the higher the visual acuity. However, the cycle-to-cycle variability of the eye position and velocity during foveation periods also contribute to visual acuity. A high variability of the eye position during the foveations hinders a stable placement of the target image on the centralmost fovea and consequently decreases visual acuity. To investigate the relationship between different nystagmus features and visual acuity, infrared- oculographic and electro-oculographic eye position recordings of 20 patients affected by congenital nystagmus were analysed in different gaze positions. In several patients' recordings, a high variability of the eye position during foveations (i.e. greater than 0.5°) was detected. Correspondingly, low visual acuity was measured, in spite of sufficiently long foveation periods. The standard deviation of eye positions during foveation periods was used to measure this variability and it was found to be correlated to visual acuity, in conjunction with the mean duration of the foveation periods. On the basis of the data analysis, an exponential relationship is proposed to relate visual acuity and the standard deviation of the eye position during foveations.},
author = {Cesarelli, M and Bifulco, P and Loffredo, L and Bracale, M},
doi = {10.1023/A:1002702609387},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Documenta Ophthalmologica/2000/Cesarelli et al/Cesarelli et al. - 2000 - Relationship between visual acuity and eye position variability during foveations in congenital nystagmus.pdf:pdf},
journal = {Documenta Ophthalmologica},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
number = {1},
pages = {59--72},
title = {{Relationship between visual acuity and eye position variability during foveations in congenital nystagmus}},
url = {http://link.springer.com/article/10.1023/A:1002702609387},
volume = {101},
year = {2000}
}
@inproceedings{Danisman2010,
abstract = {This paper presents an automatic drowsy driver monitoring and accident prevention system that is based on monitoring the changes in the eye blink duration. Our proposed method detects visual changes in eye locations using the proposed horizontal symmetry feature of the eyes. Our new method detects eye blinks via a standard webcam in real-time at 110fps for a 320×240 resolution. Experimental results in the JZU eye-blink database showed that the proposed system detects eye blinks with a 94\% accuracy with a 1\% false positive rate.},
author = {Danisman, Taner and Bilasco, Ian M and Djeraba, Chabane and Ihaddadene, Nacim},
booktitle = {2010 International Conference on Machine and Web Intelligence},
doi = {10.1109/ICMWI.2010.5648121},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 International Conference on Machine and Web Intelligence/2010/Danisman et al/Danisman et al. - 2010 - Drowsy driver detection system using eye blink patterns.pdf:pdf},
isbn = {978-1-4244-8608-3},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = oct,
pages = {230--233},
publisher = {IEEE},
title = {{Drowsy driver detection system using eye blink patterns}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5648121 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5648121},
year = {2010}
}
@inproceedings{Divjak2008,
address = {Leeds, UK},
author = {Divjak, M and Bischof, H},
booktitle = {First International Workshop on Tracking Humans for the Evaluation of their Motion in Image Sequences - THEMIS},
file = {:home/acmt/Dropbox/Documentos/Mendeley/First International Workshop on Tracking Humans for the Evaluation of their Motion in Image Sequences - THEMIS/2008/Divjak, Bischof/Divjak, Bischof - 2008 - Real-time video-based eye blink analysis for detection of low blink-rate during computer use.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {99--107},
title = {{Real-time video-based eye blink analysis for detection of low blink-rate during computer use}},
url = {http://iselab.cvc.uab.es/themis2008/ProceedingsTHEMIS2008.pdf\#page=107},
year = {2008}
}
@inproceedings{Divjak2009,
address = {Tokyo, Japan},
author = {Divjak, M and Bischof, H},
booktitle = {IAPR Conference on Machine Vision Applications - MVA},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IAPR Conference on Machine Vision Applications - MVA/2009/Divjak, Bischof/Divjak, Bischof - 2009 - Eye Blink Based Fatigue Detection for Prevention of Computer Vision Syndrome.pdf:pdf},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
pages = {350--353},
title = {{Eye Blink Based Fatigue Detection for Prevention of Computer Vision Syndrome.}},
url = {http://www.mva-org.jp/Proceedings/2009CD/papers/10-04.pdf},
year = {2009}
}
@article{Dorr2010,
abstract = {How similar are the eye movement patterns of different subjects when free viewing dynamic natural scenes? We collected a large database of eye movements from 54 subjects on 18 high-resolution videos of outdoor scenes and measured their variability using the Normalized Scanpath Saliency, which we extended to the temporal domain. Even though up to about 80\% of subjects looked at the same image region in some video parts, variability usually was much greater. Eye movements on natural movies were then compared with eye movements in several control conditions. "Stop-motion" movies had almost identical semantic content as the original videos but lacked continuous motion. Hollywood action movie trailers were used to probe the upper limit of eye movement coherence that can be achieved by deliberate camera work, scene cuts, etc. In a "repetitive" condition, subjects viewed the same movies ten times each over the course of 2 days. Results show several systematic differences between conditions both for general eye movement parameters such as saccade amplitude and fixation duration and for eye movement variability. Most importantly, eye movements on static images are initially driven by stimulus onset effects and later, more so than on continuous videos, by subject-specific idiosyncrasies; eye movements on Hollywood movies are significantly more coherent than those on natural movies. We conclude that the stimuli types often used in laboratory experiments, static images and professionally cut material, are not very representative of natural viewing behavior. All stimuli and gaze data are publicly available at http://www.inb.uni-luebeck.de/tools-demos/gaze.},
annote = {- cited by:71
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Dorr, Michael and Martinetz, Thomas and Gegenfurtner, Karl R and Barth, Erhardt},
doi = {10.1167/10.10.28},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of vision/2010/Dorr et al/Dorr et al. - 2010 - Variability of eye movements when viewing dynamic natural scenes.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Eye Movements,Eye Movements: physiology,Fixation,Humans,Motion Perception,Motion Perception: physiology,Ocular,Ocular: physiology,Pattern Recognition,Photic Stimulation,Visual,Visual: physiology,gaze analysis},
mendeley-tags = {gaze analysis},
month = jan,
number = {10},
pages = {28},
pmid = {20884493},
title = {{Variability of eye movements when viewing dynamic natural scenes.}},
url = {http://ww.journalofvision.org/content/10/10/28.short http://www.ncbi.nlm.nih.gov/pubmed/20884493},
volume = {10},
year = {2010}
}
@article{Erkelens1995,
abstract = {We studied the trajectories of self-paced saccades in two experimental conditions. Saccades were made between two visual targets in one condition and between the same two, not visible, positions in the other condition. Target pairs were presented which required oblique saccades of 20 or 40 deg. At least 200 saccades were made between each pair of targets. Horizontal and vertical eye movements were measured of the right eye with a scleral coil technique. We computed the angle between starting and end point of each primary saccade (effective direction). We also computed the angle between starting point and eye position when the saccade had covered a distance of 2.5 deg (initial direction). We found that variability in initial directions was two to seven times larger than variability in the effective directions. This effect was found in both experimental directions for saccades made in all tested directions. We conclude that curvedness of saccades is the result of a purposeful control strategy. The saccadic trajectories show that, initially, the eye is accelerated roughly in the direction of the target and subsequently is guided to the target. This behavior cannot be described by present models of saccade generation. We suggest that the coupling between saccadic pulse and step signals is not as tight as generally is accepted in the literature.},
author = {Erkelens, CJ and Vogels, IMLC},
doi = {10.1016/S0926-907X(05)80012-1},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Studies in Visual Information Processing/1995/Erkelens, Vogels/Erkelens, Vogels - 1995 - The initial direction and landing position of saccades.pdf:pdf},
journal = {Studies in Visual Information Processing},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {133--144},
title = {{The initial direction and landing position of saccades}},
url = {http://www.sciencedirect.com/science/article/pii/S0926907X05800121},
volume = {6},
year = {1995}
}
@article{Gale1984,
author = {Gale, AG and Johnson, F},
journal = {European Conference on Eye Movements ( \ldots},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{Operational problems in analysing eye movements}},
url = {http://books.google.com.br/books?hl=pt-BR\&lr=\&id=ryMkSMpWy8wC\&oi=fnd\&pg=PA21\&dq=Operational+problems+in+analysing+eye+movements\&ots=IS8lm4N12j\&sig=-mKAT8JQ0k1ltO5Jr0M-Nb1344U},
year = {1984}
}
@inproceedings{Galgani2009,
abstract = {Several studies have analyzed the link between mental dysfunctions and eye movements, using eye tracking techniques to determine where a person is looking, that is, the fixations. In this paper, we present a novel methodology to improve current diagnosis and evaluation methods of attention disorders. We have developed and tested several data-mining methodologies suitable for the automatic analysis and visualization of eye tracking data. In particular three novel methods of classification of subjects are proposed: (i) a method that uses expectation maximization to classify according to statistical likelihood of fixations locations; (ii) a procedure based on the Levenshtein distance method to compare sequences of fixations; and (iii) a method based on the analysis of the transitions frequencies of fixations between regions. Results of evaluation of classification accuracy are finally presented.},
address = {Nashville, TN},
author = {Galgani, Filippo and Sun, Yiwen and Lanzi, Pier Luca and Leigh, Jason},
booktitle = {2009 IEEE Symposium on Computational Intelligence and Data Mining},
doi = {10.1109/CIDM.2009.4938649},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2009 IEEE Symposium on Computational Intelligence and Data Mining/2009/Galgani et al/Galgani et al. - 2009 - Automatic analysis of eye tracking data for medical diagnosis.pdf:pdf},
isbn = {978-1-4244-2765-9},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = mar,
pages = {195--202},
publisher = {IEEE},
title = {{Automatic analysis of eye tracking data for medical diagnosis}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4938649 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4938649},
year = {2009}
}
@article{Hacisalihzade1993,
abstract = {An interactive program package for the acquisition, analysis and plotting of human eye movements is introduced. It is shown that the programs described in this paper can be used by scientists in a wide range of disciplines in spite of their different data analysis requirements. An example dealing with smooth pursuit tracking is given.},
author = {Hacisalihzade, Selim S. and Allen, John S. and Stark, Lawrence W.},
doi = {10.1016/0169-2607(93)90056-Q},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer Methods and Programs in Biomedicine/1993/Hacisalihzade, Allen, Stark/Hacisalihzade, Allen, Stark - 1993 - Computer analysis of eye movements.pdf:pdf},
issn = {01692607},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = jul,
number = {3},
pages = {181--187},
title = {{Computer analysis of eye movements}},
url = {http://www.sciencedirect.com/science/article/pii/016926079390056Q http://linkinghub.elsevier.com/retrieve/pii/016926079390056Q},
volume = {40},
year = {1993}
}
@inproceedings{Hammer2013,
abstract = {This paper presents a system for real-time analysis of 3D gaze data arising in mobile applications. Our system allows users to freely move in a known 3D environment while their gaze is computed on arbitrarily shaped objects. The scanpath is analysed fully automatically using fixations and areas-of-interest -- all in 3D and real time. Furthermore, the scanpath can be visualized in parallel in a 3D model of the environment. This enables to observe the scanning behaviour of a subject. We describe how this has been realized for a commercial off-the-shelf mobile eye tracker utilizing an inside-out tracking mechanism for head pose estimation. Moreover, we show examples of real gaze data collected in a museum.},
address = {New York, New York, USA},
author = {Hammer, Jan Hendrik and Maurus, Michael and Beyerer, J\"{u}rgen},
booktitle = {Proceedings of the 2013 Conference on Eye Tracking South Africa - ETSA '13},
doi = {10.1145/2509315.2509333},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2013 Conference on Eye Tracking South Africa - ETSA '13/2013/Hammer, Maurus, Beyerer/Hammer, Maurus, Beyerer - 2013 - Real-time 3D gaze analysis in mobile applications.pdf:pdf},
isbn = {9781450321105},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {75--78},
publisher = {ACM Press},
title = {{Real-time 3D gaze analysis in mobile applications}},
url = {http://dl.acm.org/citation.cfm?id=2509333 http://dl.acm.org/citation.cfm?doid=2509315.2509333},
year = {2013}
}
@article{Hashiba1995,
abstract = {Abnormalities of smooth pursuit eye movement (SPEM) have been estimated, mainly using the wave form on an electro-oculogram, in a qualitative way. Many methods for quantitative analysis of SPEM have been designed, though most are still uncommon in present clinical use. Using a personal computer, we developed a method of automatic quantitative analysis of ocular tracking eye movement recorded by electro-oculography (EOG). The design concept of this method is based on the observation that eye movement during ocular tracking consists of two different kinds of eye movements, one is SPEM and the other is saccade. The combination of SPEM and saccade (composite eye movement: CEM) commonly appears during ocular tracking. These two kinds of eye movement are essentially different not only in behavior but also about involved neural pathway in the central nervous system. From this point of view, we believe that the two kinds of eye movements involved in ocular tracking should be evaluated separately. The analysis method is outlined as follows. A horizontal sinusoidally moving visual target was employed to elicit ocular tracking eye movements. The test frequencies were set at 0.1, 0.2, 0.4 and 0.8Hz, and the amplitude of target motion was 15 deg at each frequency. The 20 seconds of eye movement data measured by EOG were fed into the computer through a digital-analog converter for further analysis. Using our original saccade detection algorithm, based on the physiological behavior of saccades, the saccadic components were detected and removed from the eye movement wave. The remaining parts, fragments of SPEM, were connected by means of interpolating defective parts. The reconstructed wave was a slow cumulative eye position curve (SCEP). Sinusoidal target motion, CEM and SCEP were processed by the FFT (Fast Fourier Transformation) method. Bode plots were applied to summarize the gain and phase of responses to SCEP and the target motion wave. These processes enable us to estimate abnormalities of SPEM such as low gain, abnormal phase shift and large trends in tested duration. We conclude that the method described here is useful for quantitative estimation of SPEM in clinical neuro-otological examinations.},
author = {Hashiba, M and Yasui, K and Watabe, H and Matsuoka, T and Baba, S},
issn = {0030-6622},
journal = {Nihon Jibiinkoka Gakkai kaiho},
keywords = {Adult,Algorithms,Computers,Electrooculography,Humans,Pursuit,Smooth,Smooth: physiology,gaze analysis,smooth pursuit},
mendeley-tags = {gaze analysis,smooth pursuit},
month = apr,
number = {4},
pages = {681--96},
pmid = {7782976},
title = {{[Quantitative analysis of smooth pursuit eye movement].}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7782976},
volume = {98},
year = {1995}
}
@article{Hermens2010,
abstract = {When making a saccadic eye movement to a peripheral target, a simultaneous stimulus onset at central fixation generally increases saccadic latency, while offsets reduce latency ('gap effect'). Visual onsets remote from fixation also increase latency ('remote distractor effect'); however, the influence of remote visual offsets is less clear. Previous studies, which used a search task, found that remote offsets either facilitated, inhibited, or did nothing to saccade latencies towards a peripheral target. It cannot be excluded, however, that the target selection process in such search tasks influenced the results. We therefore simplified the task and asked participants to make eye movements to a predictable target. Simultaneously with target onset, either one or multiple remote stimulus onsets and offsets were presented. It was found that peripheral onsets increased saccade latencies, but offsets did not influence the initiation of a saccade to the target. Moreover, the number of onsets and offsets did not affect the results. These results suggest that earlier effects of remote stimulus offsets and of the number of remote distractor onsets reside in the target identification process of the visual search task rather than the competition between possible saccade goals. The results are discussed in the context of models of saccade target selection.},
annote = {Ver o que est\'{a} relacionado \`{a} segmenta\c{c}\~{a}o de dados do olhar},
author = {Hermens, Frouke and Walker, Robin},
doi = {10.1068/i0392},
file = {:home/acmt/Dropbox/Documentos/Mendeley/i-Perception/2010/Hermens, Walker/Hermens, Walker - 2010 - The influence of onsets and offsets on saccade programming.pdf:pdf},
issn = {2041-6695},
journal = {i-Perception},
keywords = {eye tracking,segmentation},
mendeley-tags = {eye tracking,segmentation},
month = jan,
number = {2},
pages = {83--94},
pmid = {23397028},
publisher = {Pion Ltd},
title = {{The influence of onsets and offsets on saccade programming.}},
url = {http://i-perception.perceptionweb.com/journal/I/article/i0392 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3563056\&tool=pmcentrez\&rendertype=abstract},
volume = {1},
year = {2010}
}
@inproceedings{Holland2013a,
abstract = {This paper presents an objective evaluation of previously unexplored biometric techniques utilizing patterns identifiable in human eye movements to distinguish individuals. The distribution of primitive eye movement features are compared between eye movement recordings using algorithms based on the following statistical tests: the Ansari-Bradley test, the Mann-Whitney U-test, the two-sample Kolmogorov-Smirnov test, the two-sample t-test, and the two-sample Cramer-von Mises test. Score-level information fusion is applied and evaluated by: weighted mean, support vector machine, random forest, and likelihood ratio. The accuracy of each comparison/jusion algorithm is evaluated, with results suggesting that, on high resolution eye tracking equipment, it is possible to obtain equal error rates of 16.5\% and rank-1 identification rates of 82.6\% using the two-sample Cramér-von Mises test and score-level information fusion by random forest, the highest accuracy results on the considered dataset.},
address = {Madrid},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Holland, Corey D. and Komogortsev, Oleg V},
booktitle = {2013 International Conference on Biometrics (ICB)},
doi = {10.1109/ICB.2013.6612953},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2013 International Conference on Biometrics (ICB)/2013/Holland, Komogortsev/Holland, Komogortsev - 2013 - Complex eye movement pattern biometrics Analyzing fixations and saccades.pdf:pdf},
isbn = {978-1-4799-0310-8},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = jun,
pages = {1--8},
publisher = {IEEE},
title = {{Complex eye movement pattern biometrics: Analyzing fixations and saccades}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6612953 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6612953},
year = {2013}
}
@article{Ince2009,
abstract = {The systems let user track their eye gaze information have been technologically possible for several decades. However, they are still very expensive. They have limited use of eye tracking and blink detection infra-structure. The purpose of this paper is to evaluate cost effects in the sector and explain our new approach in detail which reduces high costs of current systems apparently. This paper introduces an algorithm for fast and sub-pixel precise detection of eye blobs for extracting eye features. The algorithm is based on differential geometry and still exists in OpenCpV library as a class. Hence, blobs of arbitrary size that means eye size can be extracted by just adjusting the scale parameter in the class function. In addition, center point and boundary of an eye blob, also are extracted. These describe the specific eye location in the face boundary to run several algorithms to find the eye-ball location with its central coordinates. Several examples on real simple web-cam images illustrate the performance of the proposed algorithm and yield an efficient result on the idea of low-cost eye tracking, blink detection and drowsiness detection system.},
author = {Ince, IF and Yang, TC},
doi = {10.1007/978-3-642-04070-2\_58},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Emerging Intelligent Computing Technology and Applications/2009/Ince, Yang/Ince, Yang - 2009 - A new low-cost eye tracking and blink detection approach extracting eye features with blob extraction.pdf:pdf},
journal = {Emerging Intelligent Computing Technology and Applications},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
pages = {526--533},
title = {{A new low-cost eye tracking and blink detection approach: extracting eye features with blob extraction}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-04070-2\_58},
volume = {5754},
year = {2009}
}
@article{Juhola,
author = {Juhola, M and Aalto, H and Joutsijoki, H and Hirvonen, TP},
file = {:home/acmt/Dropbox/Documentos/Mendeley/downloads.hindawi.com/Unknown/Juhola et al/Juhola et al. - Unknown - The Classification of Valid and Invalid Beats of Three-Dimensional Nystagmus Eye Movement Signals Using Machin.pdf:pdf},
journal = {downloads.hindawi.com},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
title = {{The Classification of Valid and Invalid Beats of Three-Dimensional Nystagmus Eye Movement Signals Using Machine Learning Methods}},
url = {http://downloads.hindawi.com/journals/aans/aip/972412.pdf}
}
@phdthesis{Karrsgard2003,
abstract = {Vision is the most complex human sense and a very important instrument for communication. A lot of knowledge about a person can be obtained by studying her eyes and it is possible to trace her true intent by observing her eye movements. In the same way as speech or handwriting analysis require accurate interpretation of the speech or the pen movements, visual impression analysis require accurate interpretation of the eye movements. In this thesis the gaze tracking system Smart Eye Pro, developed by Smart Eye AB, is evaluated in terms of its use in distinguishing small eye movements. The large amount of data obtained from the gaze tracker is refined and the thesis aims at evaluating the gain of interpreting the eye movements using hidden Markov models. An eye typing application is developed to facilitate the evaluation. In this application, the user forms a word by fixating characters on a screen in front of her. Eye typing is an interesting application since the quality of the interpretation is easy to determine and the application may be an important aid for people with a handicap that impair their ability to write.},
author = {K\"{a}rrsg\aa rd, I and Lindholm, A},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/Unknown/K\"{a}rrsg\aa rd, Lindholm/K\"{a}rrsg\aa rd, Lindholm - Unknown - Eye movement tracking using hidden Markov models.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {40},
title = {{Eye movement tracking using hidden Markov models}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.125.5895\&rep=rep1\&type=pdf}
}
@phdthesis{Kasprowski2004a,
annote = {- cited by: 19- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Kasprowski, P},
booktitle = {Faculty of Automatic Control, Electronics and \ldots},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Faculty of Automatic Control, Electronics and \ldots/2004/Kasprowski/Kasprowski - 2004 - Human identification using eye movements.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {111},
school = {Silesian University of Technology},
title = {{Human identification using eye movements}},
url = {http://www.kasprowski.pl/phd/PhD\_Kasprowski.pdf},
year = {2004}
}
@inproceedings{Koh2009,
abstract = {This paper evaluates the input performance capabilities of Velocity Threshold (I-VT) and Kalman Filter (I-KF) eye movement detection models when employed for eye-gaze-guided interface control. I-VT is a common eye movement identification model employed by the eye tracking community, but it is neither robust nor capable of handling high levels of noise present in the eye position data. Previous research implies that use of a Kalman filter reduces the noise in the eye movement signal and predicts the signal during brief eye movement failures, but the actual performance of I-KF was never evaluated. We evaluated the performance of I-VT and I-KF models using guidelines for ISO 9241 Part 9 standard, which is designed for evaluation of non keyboard/mouse input devices with emphasis on performance, comfort, and effort. Two applications were implemented for the experiment: 1) an accuracy test 2) a photo viewing application specifically designed for eye-gaze-guided control. Twenty-one subjects participated in the evaluation of both models completing a series of tasks. The results indicates that I-KF allowed participants to complete more tasks with shorter completion time while providing higher general comfort, accuracy and operation speeds with easier target selection than the I-VT model. We feel that these results are especially important to the engineers of new assistive technologies and interfaces that employ eye-tracking technology in their design.},
address = {New York, New York, USA},
annote = {- cited by: 16- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000
        
Resumo: },
author = {Koh, Do Hyong and {Munikrishne Gowda}, Sandeep A. and Komogortsev, Oleg V},
booktitle = {Proceedings of the 1st ACM SIGCHI symposium on Engineering interactive computing systems - EICS '09},
doi = {10.1145/1570433.1570470},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 1st ACM SIGCHI symposium on Engineering interactive computing systems - EICS '09/2009/Koh, Munikrishne Gowda, Komogortsev/Koh, Munikrishne Gowda, Komogortsev - 2009 - Input evaluation of an eye-gaze-guided interface.pdf:pdf},
isbn = {9781605586007},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {197},
publisher = {ACM Press},
title = {{Input evaluation of an eye-gaze-guided interface}},
url = {http://dl.acm.org/citation.cfm?id=1570470 http://portal.acm.org/citation.cfm?doid=1570433.1570470},
year = {2009}
}
@article{Komogortsev2010a,
abstract = {In an effort towards standardization, this paper evaluates the performance of five eye movement classification algorithms in terms of their assessment of oculomotor fixation and saccadic behavior. The results indicate that performance of these five commonly used algorithms vary dramatically even in the case of a simple stimulus evoked task using a single, common threshold value. The important contributions of this paper are: 1) evaluation and comparison of performance of five algorithms to classify specific oculomotor behavior 2) introduction and comparison of new standardized scores to provide more reliable classification performance 3) logic for a reasonable threshold value selection for any eye movement classification algorithm based on the standardized scores and 4) logic for establishing a criterion-based baseline for performance comparison between any eye movement classification algorithms. Proposed techniques enable efficient and objective clinical applications providing means to assure meaningful automated eye movement classification.},
annote = {- cited by: 29
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Komogortsev, Oleg V and Gobert, D V and Jayarathna, S and Koh, D-H and Gowda, S},
doi = {10.1109/TBME.2010.2057429},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on bio-medical engineering/2010/Komogortsev et al/Komogortsev et al. - 2010 - Standardization of automated analyses of oculomotor fixation and saccadic behaviors.pdf:pdf},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Analysis,baseline,eye-movement classification,gaze analysis,oculomotor behavior.},
mendeley-tags = {gaze analysis},
month = nov,
number = {11},
pages = {2635--2645},
pmid = {20667803},
title = {{Standardization of automated analyses of oculomotor fixation and saccadic behaviors.}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5523936 http://www.ncbi.nlm.nih.gov/pubmed/20667803},
volume = {57},
year = {2010}
}
@inproceedings{Komogortsev2010,
abstract = {This paper presents a set of qualitative and quantitative scores designed to assess performance of any eye movement classification algorithm. The scores are designed to provide a foundation for the eye tracking researchers to communicate about the performance validity of various eye movement classification algorithms. The paper concentrates on the five algorithms in particular: Velocity Threshold Identification (I-VT), Dispersion Threshold Identification (I-DT), Minimum Spanning Tree Identification (MST), Hidden Markov Model Identification (I-HMM) and Kalman Filter Identification (I-KF). The paper presents an evaluation of the classification performance of each algorithm in the case when values of the input parameters are varied. Advantages provided by the new scores are discussed. Discussion on what is the "best" classification algorithm is provided for several applications. General recommendations for the selection of the input parameters for each algorithm are provided.},
address = {New York, New York, USA},
annote = {- cited by: 15
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Komogortsev, Oleg V and Jayarathna, Sampath and Koh, Do Hyong and Gowda, Sandeep Munikrishne},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743682},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Komogortsev et al/Komogortsev et al. - 2010 - Qualitative and quantitative scoring and evaluation of the eye movement classification algorithms.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {65},
publisher = {ACM Press},
title = {{Qualitative and quantitative scoring and evaluation of the eye movement classification algorithms}},
url = {http://dl.acm.org/citation.cfm?id=1743682 http://portal.acm.org/citation.cfm?doid=1743666.1743682},
year = {2010}
}
@article{Komogortsev2013,
abstract = {Ternary eye movement classification, which separates fixations, saccades, and smooth pursuit from the raw eye positional data, is extremely challenging. This article develops new and modifies existing eye-tracking algorithms for the purpose of conducting meaningful ternary classification. To this end, a set of qualitative and quantitative behavior scores is introduced to facilitate the assessment of classification performance and to provide means for automated threshold selection. Experimental evaluation of the proposed methods is conducted using eye movement records obtained from 11 subjects at 1000 Hz in response to a step-ramp stimulus eliciting fixations, saccades, and smooth pursuits. Results indicate that a simple hybrid method that incorporates velocity and dispersion thresholding allows producing robust classification performance. It is concluded that behavior scores are able to aid automated threshold selection for the algorithms capable of successful classification.},
author = {Komogortsev, Oleg V and Karpov, Alex},
doi = {10.3758/s13428-012-0234-9},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2013/Komogortsev, Karpov/Komogortsev, Karpov - 2013 - Automated classification and scoring of smooth pursuit eye movements in the presence of fixations and sa(2).pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adolescent,Adult,Algorithms,Automated,Automated: methods,Biological,Eye Movement Measurements,Fixation,Humans,Models,Ocular,Pattern Recognition,Pursuit,Reaction Time,Reference Values,Saccades,Smooth,Young Adult,gaze analysis,smooth pursuit},
mendeley-tags = {gaze analysis,smooth pursuit},
month = mar,
number = {1},
pages = {203--15},
pmid = {22806708},
title = {{Automated classification and scoring of smooth pursuit eye movements in the presence of fixations and saccades.}},
url = {http://link.springer.com/article/10.3758/s13428-012-0234-9 http://www.ncbi.nlm.nih.gov/pubmed/22806708},
volume = {45},
year = {2013}
}
@article{Komogortsev2009a,
abstract = {Our work addresses one of the core issues related to Human Computer Interaction (HCI) systems that use eye gaze as an input. This issue is the sensor, transmission and other delays that exist in any eye tracker-based system, reducing its performance. A delay effect can be compensated by an accurate prediction of the eye movement trajectories. This paper introduces a mathematical model of the human eye that uses anatomical properties of the Human Visual System to predict eye movement trajectories. The eye mathematical model is transformed into a Kalman filter form to provide continuous eye position signal prediction during all eye movement types. The model presented in this paper uses brainstem control properties employed during transitions between fast (saccade) and slow (fixations, pursuit) eye movements. Results presented in this paper indicate that the proposed eye model in a Kalman filter form improves the accuracy of eye movement prediction and is capable of a real-time performance. In addition to the HCI systems with the direct eye gaze input, the proposed eye model can be immediately applied for a bit-rate/computational reduction in real-time gaze-contingent systems.},
author = {Komogortsev, Oleg V and Khan, Javed I.},
doi = {10.1007/s11768-009-7218-z},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Control Theory and Applications/2009/Komogortsev, Khan/Komogortsev, Khan - 2009 - Eye movement prediction by oculomotor plant Kalman filter with brainstem control.pdf:pdf},
issn = {1672-6340},
journal = {Journal of Control Theory and Applications},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = feb,
number = {1},
pages = {14--22},
title = {{Eye movement prediction by oculomotor plant Kalman filter with brainstem control}},
url = {http://link.springer.com/article/10.1007/s11768-009-7218-z http://link.springer.com/10.1007/s11768-009-7218-z},
volume = {7},
year = {2009}
}
@article{Komogortsev2009b,
abstract = {This paper presents a new saccade amplitude prediction model. The model is based on a Kalman filter and regression analysis. The aim of the model is to predict a saccade’s am-plitude extremely quickly, i.e., within two eye position samples at the onset of a saccade. Specifically, the paper explores saccade amplitude prediction considering one or two sam-ples at the onset of a saccade. The models’ prediction performance was tested with 35 subjects. The amplitude accuracy results yielded approximately 5.26° prediction error, while the error for direction prediction was 5.3\% for the first sample model and 1.5\% for the two samples model. The practical use of the proposed model lays in the area of real-time gaze-contingent compression and extreme eye-gaze aware interaction applications. The paper provides theoretical evaluation of the benefits of saccade amplitude prediction to the gaze-contingent multimedia compression, estimating a 21\% improvement in com-pression for short network delays.},
author = {Komogortsev, Oleg V and Ryu, YS and Koh, DH},
file = {::},
journal = {Journal of Eye Movement Research},
keywords = {Human Computer,Kalman Filter,Prediction,Saccade,eye events,saccade},
mendeley-tags = {eye events,saccade},
number = {1},
pages = {1--13},
title = {{Quick models for saccade amplitude prediction}},
url = {http://www.cs.txstate.edu/~ok11/papers\_published/2009\_JEMR\_Ko\_Ry\_Ko.pdf},
volume = {3(1)},
year = {2009}
}
@inproceedings{Kumar2007a,
abstract = {The GUIDe (Gaze-enhanced User Interface Design) project in the HCI Group at Stanford University explores how gaze information can be effectively used as an augmented input in addition to keyboard and mouse. We present three practical applications of gaze as an augmented input for pointing and selection, application switching, and scrolling. Our gaze-based interaction techniques do not overload the visual channel and present a natural, universally-accessible and general purpose use of gaze information to facilitate interaction with everyday computing devices.},
address = {New York, New York, USA},
author = {Kumar, Manu and Winograd, Terry},
booktitle = {CHI '07 extended abstracts on Human factors in computing systems - CHI '07},
doi = {10.1145/1240866.1240935},
file = {:home/acmt/Dropbox/Documentos/Mendeley/CHI '07 extended abstracts on Human factors in computing systems - CHI '07/2007/Kumar, Winograd/Kumar, Winograd - 2007 - GUIDe gaze-enhanced UI design.pdf:pdf},
isbn = {9781595936424},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1977},
publisher = {ACM Press},
title = {{GUIDe: gaze-enhanced UI design}},
url = {http://dl.acm.org/citation.cfm?id=1240935 http://portal.acm.org/citation.cfm?doid=1240866.1240935},
year = {2007}
}
@article{Laubrock2005,
abstract = {We compared effects of covert spatial-attention shifts induced with exogenous or endogenous cues on microsaccade rate and direction. Separate and dissociated effects were obtained in rate and direction measures. Display changes caused microsaccade rate inhibition, followed by sustained rate enhancement. Effects on microsaccade direction were differentially tied to cue class (exogenous vs. endogenous) and type (neutral vs. directional). For endogenous cues, direction effects were weak and occurred late. Exogenous cues caused a fast direction bias towards the cue (i.e., early automatic triggering of saccade programs), followed by a shift in the opposite direction (i.e, controlled inhibition of cue-directed saccades, leading to a ‘leakage’ of microsaccades in the opposite direction).},
author = {Laubrock, Jochen and Engbert, Ralf and Kliegl, Reinhold},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2005/Laubrock, Engbert, Kliegl/Laubrock, Engbert, Kliegl - 2005 - Microsaccade dynamics during covert attention.pdf:pdf},
journal = {Vision Research},
keywords = {Attention,Eye movements,Fixation,Reaction time,gaze analysis: microsaccade},
mendeley-tags = {gaze analysis: microsaccade},
number = {6},
pages = {721--730},
title = {{Microsaccade dynamics during covert attention}},
url = {http://www.sciencedirect.com/science/article/pii/S004269890400495X},
volume = {45},
year = {2005}
}
@inproceedings{Levin2008,
abstract = {Modern geospatial data acquisition systems deliver vast amounts of multi-domain remotely sensed data such as multi/hyper spectral imagery and LIDAR point-clouds. Unfortunately geospatial products automatically derived from source geospatial data are burdened with residual errors and artifacts which should be manually inspected, cleaned and corrected. These tasks become critical in many large-scale projects that require real-time processing of immense amounts of visual information and usually require manual post-processing or visual inspection of the source and/or derived data. The process of visual inspection could be divided in two general phases: perception and reaction. Scene perception comprises several steps such as visual search, feature selection and identification. Reaction reflects a decision made by an operator and usually involves other types of modalities (e.g. physical action such as mouse movements or typing). Human analysts perceive visual data through intensive movements of eyes which subconsciously select the most distinctive features in an image in order to reduce our overall ambiguity about the observed scene. A sequence of eye movements may then be understood within a framework of sequential accumulation of information. Whether or not all informative points are detected depends on both the observer’s current knowledge of the stimulus and the particular task. Dynamics of this information accrual process can be documented and quantified using analysis of eye movements during the process of natural, active visual perception. This paper presents theoretical and practical investigations that have been made to illustrate the feasibility of 3D gaze tracking as a disambiguation tool in the process of visual search of a target in high resolution imagery.},
address = {Portland},
annote = {- cited by: 5
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Levin, E and Helton, W and Liimakka, R and Gienko, G},
booktitle = {Proceedings of ASPRS Annual Conference},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of ASPRS Annual Conference/2008/Levin et al/Levin et al. - 2008 - Eye movement analysis in visual inspection of geospatial data.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{Eye movement analysis in visual inspection of geospatial data}},
url = {http://www.asprs.org/a/publications/proceedings/portland08/0050.pdf},
year = {2008}
}
@article{Mantiuk2013,
abstract = {In this paper we model the process of temporal adaptation of the human visual system to varying luminance conditions. An eye tracker is used to capture the location of an observer’s gaze in a high dynamic range image displayed on the screen. We apply a novel technique of eye tracker data filtering to avoid flickering caused by incorrect gaze estimation. Temporary adaptation luminance is then determined in the area surrounding the gaze point. We use its value to compress the high dynamic range image and display it on the low dynamic range display. The applied tone mapping technique uses a global compression curve in which location is shifted along the luminance axis according to a value of the adaptation luminance. This technique models the natural process of adaptation occurring in the human eyes, also taking into account the time-dependent visual adaptation to dark and bright backgrounds.},
author = {Mantiuk, R and Markowski, M},
doi = {10.1007/978-3-642-39094-4\_48},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Image Analysis and Recognition/2013/Mantiuk, Markowski/Mantiuk, Markowski - 2013 - Gaze-Dependent Tone Mapping.pdf:pdf},
journal = {Image Analysis and Recognition},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {426--433},
title = {{Gaze-Dependent Tone Mapping}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-39094-4\_48},
volume = {7950},
year = {2013}
}
@inproceedings{Martinez2006,
abstract = {This paper describes the tasks carried out to develop a control tool using the changes detected in gaze, which are captured in the electrooculogram signal. The objective is to use these changes to control a user interface such as Dasher. A software tool for generating visual stimuli and acquiring the eye signal has been developed. These signals were later processed with a first derivative-based algorithm in order to detect the changes. The optimal parameters for the algorithm have been determined, and also the sensitivity (S>97\%) and the predictive positive value (+PV>90\%) of the detector have also been calculated. The preliminary results are promising, but a study with a greater number of individuals should be made to check the on-line performance with longer registers.},
address = {Tenerife, Canary Islands, Spain},
author = {Martinez, M and Soria, E and Magdalena, R},
booktitle = {Proceedings of the 6th WSEAS international conference on Applied computer science},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 6th WSEAS international conference on Applied computer science/2006/Martinez, Soria, Magdalena/Martinez, Soria, Magdalena - 2006 - Identification of saccades in Electrooculograms and their use as a control tool.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {291--295},
title = {{Identification of saccades in Electrooculograms and their use as a control tool}},
url = {http://www.wseas.us/e-library/conferences/2006tenerife/papers/541-212.pdf},
year = {2006}
}
@article{Morris2002,
abstract = {This work is motivated by our goal of providing non-contact head and eye based control of computer systems for people with motor difficulties. The system described here uses spatio-temporal filtering and variance maps to locate the head and find the eye-feature points, respectively. These feature points are accurately tracked in the succeeding frames by using a modified version of the Lucas–Kanade tracking algorithm with pyramidal implementation. Accurate head and eye tracking results are obtained at a processing rate of more than 30 frames per second (fps) in more than 90\% cases with a low false positive blink detection rate of 0.01\%. This is achieved under varying lighting conditions for people of different ethnicity, with and without wearing glasses.},
author = {Morris, T and Blenkhorn, P and Zaidi, Farhan},
doi = {10.1006/jnca.2002.0130},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Network and Computer Applications/2002/Morris, Blenkhorn, Zaidi/Morris, Blenkhorn, Zaidi - 2002 - Blink detection for real-time eye tracking.pdf:pdf},
issn = {10848045},
journal = {Journal of Network and Computer Applications},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = apr,
number = {2},
pages = {129--143},
title = {{Blink detection for real-time eye tracking}},
url = {http://www.sciencedirect.com/science/article/pii/S108480450290130X http://linkinghub.elsevier.com/retrieve/pii/S108480450290130X},
volume = {25},
year = {2002}
}
@article{Muczynski2013,
abstract = {The following paper provides information about eye-tracking techniques and methodology. It is focused on introducing eye movement metrics in human factor research in maritime domain, explaining basic methodo- logy and describing the types of data analysis, thus providing the background and guidelines for simple eye- tracking studies.},
author = {Muczyński, B and Gucma, M},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Scientific Journals Maritime \ldots/2013/Muczyński, Gucma/Muczyński, Gucma - 2013 - Application of eye-tracking techniques in human factor research in marine operations. Challenges and methodol.pdf:pdf},
journal = {Scientific Journals Maritime \ldots},
keywords = {data analy-,eye-tracking,gaze analysis,human factor research,maritime operations,sis,technique methodology},
mendeley-tags = {gaze analysis},
number = {1},
pages = {116--120},
title = {{Application of eye-tracking techniques in human factor research in marine operations. Challenges and methodology}},
url = {http://repository.am.szczecin.pl/handle/123456789/541},
volume = {36},
year = {2013}
}
@book{Nakano2013,
address = {London},
doi = {10.1007/978-1-4471-4784-8},
editor = {Nakano, Yukiko I. and Conati, Cristina and Bader, Thomas},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2013/Unknown/Unknown - 2013 - Eye Gaze in Intelligent User Interfaces.pdf:pdf},
isbn = {978-1-4471-4783-1},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
publisher = {Springer London},
title = {{Eye Gaze in Intelligent User Interfaces}},
url = {http://www.springerlink.com/index/10.1007/978-1-4471-4784-8},
year = {2013}
}
@article{Nystrom2010,
abstract = {Event detection is used to classify recorded gaze points into periods of fixation, saccade, smooth pursuit, blink, and noise. Although there is an overall consensus that current algorithms for event detection have serious flaws and that a de facto standard for event detection does not exist, surprisingly little work has been done to remedy this problem. We suggest a new velocity-based algorithm that takes several of the previously known limitations into account. Most important, the new algorithm identifies so-called glissades, a wobbling movement at the end of many saccades, as a separate class of eye movements. Part of the solution involves designing an adaptive velocity threshold that makes the event detection less sensitive to variations in noise level and the algorithm settings-free for the user. We demonstrate the performance of the new algorithm on eye movements recorded during reading and scene perception and compare it with two of the most commonly used algorithms today. Results show that, unlike the currently used algorithms, fixations, saccades, and glissades are robustly identified by the new algorithm. Using this algorithm, we found that glissades occur in about half of the saccades, during both reading and scene perception, and that they have an average duration close to 24 msec. Due to the high prevalence and long durations of glissades, we argue that researchers must actively choose whether to assign the glissades to saccades or fixations; the choice affects dependent variables such as fixation and saccade duration significantly. Current algorithms do not offer this choice, and their assignments of each glissade are largely arbitrary.},
annote = {- keyword coletado
- cited by: 65
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000

        

      },
author = {Nystr\"{o}m, Marcus and Holmqvist, Kenneth},
doi = {10.3758/BRM.42.1.188},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2010/Nystr\"{o}m, Holmqvist/Nystr\"{o}m, Holmqvist - 2010 - An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data.pdf:pdf},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Algorithms,Eye Tracking,Fixation,Humans,Models,Ocular,Psychological,Saccades,Saccades: physiology,Segmentation,Signal Detection,gaze analysis},
mendeley-tags = {Eye Tracking,gaze analysis,Segmentation},
month = feb,
number = {1},
pages = {188--204},
pmid = {20160299},
title = {{An adaptive algorithm for fixation, saccade, and glissade detection in eyetracking data.}},
url = {http://link.springer.com/article/10.3758/BRM.42.1.188 http://www.ncbi.nlm.nih.gov/pubmed/20160299},
volume = {42},
year = {2010}
}
@techreport{Olsen2012,
abstract = {This document describes the general principles behind an I-VT fixation filter and they are implemented in the Tobii I-VT Fixation Filter.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Olsen, A},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2012/Olsen/Olsen - 2012 - The Tobii I-VT Fixation Filter.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {21},
title = {{The Tobii I-VT Fixation Filter}},
url = {http://www.tobii.com/Global/Analysis/Training/WhitePapers/Tobii\_WhitePaper\_TobiiIVTFixationFilter.pdf},
year = {2012}
}
@inproceedings{Olsen2012a,
abstract = {Selecting values for fixation filters is a difficult task as not only the specifics of the selected filter algorithm has to be taken into account, but also what it is going to be used for and by whom. In this paper the selection and testing process of values for an I-VT fixation filter algorithm implementation is described.},
address = {New York, New York, USA},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Olsen, Anneli and Matos, Ricardo},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12},
doi = {10.1145/2168556.2168625},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12/2012/Olsen, Matos/Olsen, Matos - 2012 - Identifying parameter values for an I-VT fixation filter suitable for handling data sampled with various sampling.pdf:pdf},
isbn = {9781450312219},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {317},
publisher = {ACM Press},
title = {{Identifying parameter values for an I-VT fixation filter suitable for handling data sampled with various sampling frequencies}},
url = {http://dl.acm.org/citation.cfm?id=2168625 http://dl.acm.org/citation.cfm?doid=2168556.2168625},
year = {2012}
}
@phdthesis{Olsson2007,
abstract = {An eye tracker makes it possible to record the gaze point of a person looking at for example a computer monitor. Modern techniques are very flexible and allow the user to behave naturally without the need of cumbersome equipment such as special contact lenses or electrical probes. This is valuable in psychological research, marketing research and Human Computer Interaction. Eye trackers also give people who are severely paralyzed and unable to type and speak means to communicate using their eyes. Measurement noise makes the use of digital filters necessary. An example is an eye-controlled cursor for a desktop environment such as Windows. The cursor has to be stable enough to allow the user to select folders, icons or other items of interest. While this type of application requires a fast real-time filter, others are less sensitive to processing time but demand an even higher level of accuracy. This work explores three areas of eye tracking filtration and aims at enhancing the performance of the filters used in the eye tracking systems built by Tobii Technology, Sweden. First, a post-processing algorithm to find fixations in raw gaze data is detailed. Second, modifications to an existing reading detection algorithm are described to make it more robust to natural irregularities in reading patterns. Third, a real-time filter for an eye-controlled cursor to be used in a desktop environment is designed using a low-pass filter in parallel with a change detector. The fixation filter produced fewer false fixations and was also able to detect fixations lying spatially closer together than the previously used filter. The reading detection algorithm was shown to be robust to natural irregularities in reading such as revisits to previously read text or skipped paragraphs. The eye-cursor filter proved to respond quicker than the previously used moving average filter while maintaining a high level of noise attenuation.},
address = {Stockholm, Sweden},
annote = {- crossRef (Larsson2010)},
author = {Olsson, Pontus},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2007/Olsson/Olsson - 2007 - Real-time and Offline Filters for Eye Tracking.pdf:pdf},
keywords = {Control Engineering,Reglerteknik,Technology,eye tracking,gaze analysis,teknik},
language = {eng},
mendeley-tags = {eye tracking,gaze analysis},
pages = {45},
publisher = {KTH Electrical Engineering},
school = {KTH Electrical Engineering},
title = {{Real-time and Offline Filters for Eye Tracking}},
url = {http://kth.diva-portal.org/smash/record.jsf?pid=diva2:573446},
year = {2007}
}
@article{Oyekoya2006,
abstract = {Eye-tracking technology offers a natural and immediate way of communicating human intentions to a computer. Eye movements reflect interests and may be analysed to drive computer functionality in games, image and video search, and other visual tasks. This paper examines current eye tracking technologies and their applications. Experiments are described that show that target images can be identified more rapidly by eye tracking than using a mouse interface. Further results show that an eye-tracking technology provides an efficient interface for locating images in a large database. Finally the paper speculates about how the technology may enter the mass market as costs decrease.},
author = {Oyekoya, O. K. and Stentiford, F. W. M.},
doi = {10.1007/s10550-006-0076-z},
file = {:home/acmt/Dropbox/Documentos/Mendeley/BT Technology Journal/2006/Oyekoya, Stentiford/Oyekoya, Stentiford - 2006 - Eye tracking — A new interface for visual exploration.pdf:pdf},
issn = {1358-3948},
journal = {BT Technology Journal},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = jul,
number = {3},
pages = {57--66},
title = {{Eye tracking — A new interface for visual exploration}},
url = {http://link.springer.com/article/10.1007/s10550-006-0076-z http://link.springer.com/10.1007/s10550-006-0076-z},
volume = {24},
year = {2006}
}
@incollection{Oyekoya2006a,
abstract = {The best interfaces are the most natural ones. They are unobtrusive and provide relevant information quickly and in ways that do not interfere with the task itself.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Oyekoya, OK and Stentiford, FWM},
booktitle = {Intelligent Spaces},
doi = {10.1007/978-1-84628-429-8\_17},
edition = {17},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Intelligent Spaces/2006/Oyekoya, Stentiford/Oyekoya, Stentiford - 2006 - Eye Tracking as a New Interface for Image Retrieval.pdf:pdf},
isbn = {978-1-84628-429-8},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {273--286},
publisher = {Springer London},
title = {{Eye Tracking as a New Interface for Image Retrieval}},
url = {http://link.springer.com/content/pdf/10.1007/978-1-84628-429-8\_17.pdf},
year = {2006}
}
@inproceedings{Radinsky2004,
abstract = {An improved algorithm for classification of nystagmus was designed allowing the sorting of response segments even in severely non-linear patients and subjects with abnormally large phase shifts. The algorithm employs a model-based approach that was developed by Rey and Galiana. The improved classification algorithm consists of two essential stages. In the first stage the eye velocity response is classified to obtain initial estimates of the slow phase eye velocity intervals. In the second stage, the slow phase estimates are used to identify a response phase shift and nonlinearity, and compensate for their effects. Multiple tests on simulated data and experimental data obtained from clinical subjects are presented. The results of the tests demonstrate that the algorithm is able to analyze the patient data with a high accuracy even in the presence of noise, eye-blinks and other artifacts.},
address = {San Francisco, CA},
author = {Radinsky, Iliya and Galiana, Henrietta L},
booktitle = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
doi = {10.1109/IEMBS.2004.1403212},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Conference proceedings ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engine. Conference/2004/Radinsky, Galiana/Radinsky, Galiana - 2004 - Improved algorithm for classification of ocular nystagmus.pdf:pdf},
issn = {1557-170X},
keywords = {gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = jan,
pages = {534--537},
pmid = {17271731},
title = {{Improved algorithm for classification of ocular nystagmus.}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1403212 http://www.ncbi.nlm.nih.gov/pubmed/17271731},
volume = {1},
year = {2004}
}
@incollection{Regis2012,
abstract = {This paper focuses on ocular measurement to detect the human operator’s particular state of “attentional tunnelling” during a robot supervisory task. After a survey of the existing ocular metrics, an innovative fixation detection algorithm is proposed. Then the metrics derived from the ocular parameters calculated by the algorithm are tested in a human-robot experiment. Among the metrics calculated, 3 of them appear to be able to statisticaly discrimintate the operators who faced attentional tunnelling.},
address = {Toulouse, France.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Regis, N and Dehais, F and Tessier, C and Giagnon, J. F.},
booktitle = {Human Factors and Ergonomics Society},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Human Factors and Ergonomics Society/2012/Regis et al/Regis et al. - 2012 - Ocular metrics for detecting attentional tunnelling.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {121--132},
title = {{Ocular metrics for detecting attentional tunnelling}},
url = {http://www.hfes-europe.org/books/proceedings2012/regis.pdf},
year = {2012}
}
@article{Renshaw2004,
abstract = {We describe an experiment in which the eye movements of participants, carrying out tasks using two contrasting graph designs, were recorded by means of a remote eye tracking device. A variety of eye movement properties were measured and analysed both temporally and spatially. Both graph designs were based on specific psychological theories and established graph design guidelines. One incorporated attributes thought likely to enhance usability, the other included attributes likely to have the opposite effect. The results demonstrate that the design and location of a graph's legend and its spatial relationship to the data area are extremely important in determining a graph's usability. The incorporation of these and other design features may promote or detract from perceptual proximity and therefore influence a display's usability. The paper demonstrates that this influence is reflected in eye movement patterns, which can be readily monitored by means of a remote eye tracking system, and that a relatively simple temporal analysis of the results can give important insights as to how the usability of visual displays has been influenced.},
annote = {- cited by: 26
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Renshaw, J.A and Finlay, J.E and Tyfa, D and Ward, R.D},
doi = {10.1016/j.intcom.2004.03.001},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Interacting with Computers/2004/Renshaw et al/Renshaw et al. - 2004 - Understanding visual influence in graph design through temporal and spatial eye movement characteristics.pdf:pdf},
journal = {Interacting with Computers},
keywords = {Eye tracking,Graphs,Perception,Usability,gaze analysis},
mendeley-tags = {gaze analysis},
number = {3},
pages = {557--578},
title = {{Understanding visual influence in graph design through temporal and spatial eye movement characteristics}},
url = {http://www.sciencedirect.com/science/article/pii/S0953543804000360},
volume = {16},
year = {2004}
}
@article{Rigas2012,
abstract = {The last few years a growing research interest has aroused in the field of biometrics, concerning the use of brain dependent characteristics generally known as behavioral features. Human eyes, often referred as the gates to the soul, can possibly comprise a rich source of idiosyncratic information which may be used for the recognition of an individual’s identity. In this paper an innovative experiment and a novel processing approach for the human eye movements is implemented, ultimately aiming at the biometric segregation of individual persons. In our experiment, the subjects observe face images while their eye movements are being monitored, providing information about each participant’s attention spots. The implemented method treats eye trajectories as 2-D distributions of points on the image plane. The efficiency of graph objects in the representation of structural information motivated us on the utilization of a non-parametric multivariate graph-based measure for the comparison of eye movement signals, yielding promising results at the task of identification according to behavioral characteristics of an individual.},
author = {Rigas, Ioannis and Economou, George and Fotopoulos, Spiros},
doi = {10.1016/j.patrec.2012.01.003},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2012/Rigas, Economou, Fotopoulos/Rigas, Economou, Fotopoulos - 2012 - Biometric identification based on the eye movements and graph matching techniques.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = apr,
number = {6},
pages = {786--792},
title = {{Biometric identification based on the eye movements and graph matching techniques}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865512000062 http://linkinghub.elsevier.com/retrieve/pii/S0167865512000062},
volume = {33},
year = {2012}
}
@article{Salojarvi2005,
abstract = {We organize a PASCAL EU Network of Excellence challenge for inferring relevance from eye movements, beginning 1 March 2005. The aim of this paper is to provide background material for the competitors: give references to related articles on eye movement modelling, describe the methods used for extracting the features used in the challenge, provide results of basic reference methods and to discuss open questions in the field.},
annote = {- cited by: 27
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Saloj\"{a}rvi, J and Puolam\"{a}ki, K and Simola, J and Kovanen, L},
doi = {10.1.1.96.6356},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2005/Saloj\"{a}rvi et al/Saloj\"{a}rvi et al. - 2005 - Inferring relevance from eye movements Feature extraction.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
title = {{Inferring relevance from eye movements: Feature extraction}},
url = {http://eprints.pascal-network.org/archive/00000963/},
year = {2005}
}
@inproceedings{Salvucci2000a,
abstract = {This paper describes EyeTracer, an interactive environment for manipulating, viewing, and analyzing eye-movement protocols. EyeTracer augments the typical functionality of such systems by incorporating model-based tracing algorithms that interpret protocols with respect to the predictions of a cognitive process model. These algorithms provide robust strategy classification and fixation assignment that help to alleviate common difficulties with eye-movement data, such as equipment noise and individual variability. Using the tracing algorithms for analysis and visualization, EyeTracer facilitates both exploratory analysis for initial understanding of behavior and confirmatory analysis for model evaluation and refinement.},
address = {New York, New York, USA},
annote = {- cited by: 27
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Salvucci, Dario D.},
booktitle = {Proceedings of the symposium on Eye tracking research \& applications - ETRA '00},
doi = {10.1145/355017.355026},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the symposium on Eye tracking research \& applications - ETRA '00/2000/Salvucci/Salvucci - 2000 - An interactive model-based environment for eye-movement protocol analysis and visualization.pdf:pdf},
isbn = {1581132808},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {57--63},
publisher = {ACM Press},
title = {{An interactive model-based environment for eye-movement protocol analysis and visualization}},
url = {http://dl.acm.org/citation.cfm?id=355026 http://portal.acm.org/citation.cfm?doid=355017.355026},
year = {2000}
}
@inproceedings{Salvucci2000,
abstract = {The process of fixation identification—separating and labeling fixations and saccades in eye-tracking protocols—is an essential part of eye-movement data analysis and can have a dramatic impact on higher-level analyses. However, algorithms for performing fixation identification are often described informally and rarely compared in a meaningful way. In this paper we propose a taxonomy of fixation identification algorithms that classifies algorithms in terms of how they utilize spatial and temporal information in eye-tracking protocols. Using this taxonomy, we describe five algorithms that are representative of different classes in the taxonomy and are based on commonly employed techniques. We then evaluate and compare these algorithms with respect to a number of qualitative characteristics. The results of these comparisons offer interesting implications for the use of the various algorithms in future work.},
address = {New York, New York, USA},
annote = {- keyword coletado
        
Resumo: Salvucci [@Salvucci2000] introduz uma taxonomia de algoritmos de identifica\c{c}\~{a}o de fixa\c{c}\~{o}es e sacadas. Esta taxonomia \'{e} baseada em como s\~{a}o usadas as informa\c{c}\~{o}es de tempo e espa\c{c}o. Os algoritmos citados no artigo representam classes de t\'{e}cnicas que compartilham algum crit\'{e}rio de identifica\c{c}\~{a}o. Ele tamb\'{e}m apresenta uma forma de analisar os algoritmos de maneira qualitativa: facilidade de uso, velocidade de interpreta\c{c}\~{a}o, acur\'{a}cia, robustez, e parametriza\c{c}\~{a}o.
        
        I-VT:
Vantagens:        
- f\'{a}cil de implementar
- eficiente
- pode ser executado em tempo real
        Desvantagens:        
- inst\'{a}vel em pontos com velocidade pr\'{o}xima do threshold (precisa lidar com o ru\'{\i}do do equipamento e movimentos do olhar  irrelevantes para a pesquisa).
- Pode provocar altern\^{a}ncias entre classifica\c{c}\~{o}es, implicando em fixa\c{c}\~{o}es e sacadas com poucos pontos, aumentando o n\'{u}mero de fixa\c{c}\~{o}es exclu\'{\i}das pelo crit\'{e}rio de dura\c{c}\~{a}o m\'{\i}nima. 
- N\~{a}o \'{e} robusto.
- Persegui\c{c}\~{o}es podem ser classificados como fixa\c{c}\~{o}es ou sacadas dependendo de sua velocidade.
        
        I-HMM
Vantagens:
        - Modelo probabil\'{\i}stico ao inv\'{e}s de um threshold. Utiliza informa\c{c}\~{a}o sequencial (os vizinhos influenciam o ponto).
- \'{E} mais robusto na presen\c{c}a do ru\'{\i}do.
- Pode expandir o diagrama de estados (incorporando mais movimentos do olhar)
- \'{E} executado em tempo linear e pode ser executado em tempo real.
        Desvantagens:        
- Mais complexo que I-VT.
- Procedimento de reestimar os par\^{a}metros tamb\'{e}m \'{e} complexo.
                  
I-DT
Vantagens:        
- Algoritmo simples
- Tempo linear;
- Tempo real;
- Evita a           
Desvantagens:        
- Par\^{a}metros interdependentes (ex: dura\c{c}\~{a}o m\'{\i}nima alta e limiar de dispers\~{a}o baixa pode n\~{a}o classificar nenhuma fixa\c{c}\~{a}o)
- Sens\'{\i}vel a ru\'{\i}do (pode ultrapassar o limiar)
                  
I-MST
Vantagens:        
- Robusto (pode usar vari\^{a}ncia e m\'{e}dia para lidar com ru\'{\i}do)
- Cria clusters de fixa\c{c}\~{o}es
- 
                  
Desvantagens:        
- Lento (tempo de execu\c{c}\~{a}o exponencial)
- Para cada ponto adicionado, \'{e} necess\'{a}rio achar o ponto mais pr\'{o}ximo dentre v\'{a}rios para restruturar o cluster e separar os clusters.
                  
I - AOI
Vantagens:        
- Tempo real
- Simples
                  
Desvantagens:        
- N\~{a}o lida bem com sacadas (inclu\'{\i}das nas fixa\c{c}\~{o}es se estiverem dentro das regi\~{o}es), aumentando a dura\c{c}\~{a}o da fixa\c{c}\~{a}o.
- Longas sacadas s\~{a}o consideradas fixa\c{c}\~{o}es nas regi\~{o}es intermedi\'{a}rias.
- Depende da aplica\c{c}\~{a}o (distribui\c{c}\~{a}o das regi\~{o}es)},
author = {Salvucci, Dario D. and Goldberg, Joseph H.},
booktitle = {Proceedings of the symposium on Eye tracking research \& applications - ETRA '00},
doi = {10.1145/355017.355028},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the symposium on Eye tracking research \& applications - ETRA '00/2000/Salvucci, Goldberg/Salvucci, Goldberg - 2000 - Identifying fixations and saccades in eye-tracking protocols.pdf:pdf},
isbn = {1581132808},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
pages = {71--78},
publisher = {ACM Press},
title = {{Identifying fixations and saccades in eye-tracking protocols}},
url = {http://dl.acm.org/citation.cfm?id=355028 http://portal.acm.org/citation.cfm?doid=355017.355028},
year = {2000}
}
@article{Smeets2003,
abstract = {We studied the variability in saccades by comparing the peak velocities of saccades with the same target amplitude made with different actual amplitudes. We tested three hypotheses: the pulse-height noise hypothesis (peak velocity and amplitude vary proportionally), the localization noise hypothesis (variability in amplitude and peak velocity lie along the main sequence), and the independent noise hypothesis (variability in amplitude and peak velocity are independent). We measured eye orientation in two experiments by a scleral coil and a video system. Surprisingly, the main source of variability of saccades depended on the measurement system used. A combination of localization noise and independent noise best describes the data obtained by the video system. The independent noise (e.g., measurement inaccuracy) was the main source of variability. For the scleral coils, the variability was considerably larger than for the less accurate video system. The pulse-height noise hypothesis best describes this additional variability. Therefore we conclude that pulse-height noise is the main source of variability in saccades measured with scleral coils. We discuss the influence of scleral coils on saccade generation and suggest that a change in motor strategy due to the discomfort of wearing the coils might be the cause of the increased variability.},
annote = {- cited by: 35
- kw: Nature of variability in saccades
- engine: Google Scholar
- crossref: Larsson2010},
author = {Smeets, JBJ and Hooge, ITC},
doi = {10.​1152/​jn.​01075.​2002},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of neurophysiology/2003/Smeets, Hooge/Smeets, Hooge - 2003 - Nature of variability in saccades.pdf:pdf},
journal = {Journal of neurophysiology},
keywords = {gaze analysis,saccade},
mendeley-tags = {gaze analysis,saccade},
number = {1},
pages = {12--20},
title = {{Nature of variability in saccades}},
url = {http://jn.physiology.org/content/90/1/12.short},
volume = {90},
year = {2003}
}
@article{Tafaj2013,
abstract = {Complex and hazardous driving situations often arise with the delayed perception of traffic objects. To automatically detect whether such objects have been perceived by the driver, there is a need for techniques that can reliably recognize whether the driver’s eyes have fixated or are pursuing the hazardous object (i.e., detecting fixations, saccades, and smooth pursuits from raw eye tracking data). This paper presents a system for analyzing the driver’s visual behavior based on an adaptive online algorithm for detecting and distinguishing between fixation clusters, saccades, and smooth pursuits.},
author = {Tafaj, E and K\"{u}bler, TC and Kasneci, G},
doi = {10.1007/978-3-642-40728-4\_56},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Artificial Neural Networks and Machine Learning - ICANN/2013/Tafaj, K\"{u}bler, Kasneci/Tafaj, K\"{u}bler, Kasneci - 2013 - Online Classification of Eye Tracking Data for Automated Analysis of Traffic Hazard Perception.pdf:pdf},
journal = {Artificial Neural Networks and Machine Learning - ICANN},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {442--450},
title = {{Online Classification of Eye Tracking Data for Automated Analysis of Traffic Hazard Perception}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-40728-4\_56},
volume = {8131},
year = {2013}
}
@article{Takahashi1983,
abstract = {The effects of a change in target speed (10°–100°/s) and amplitude (10°–80°) on smooth pursuit eye movements were analyzed in normal subjects by moving a target unidirectionally. The limit of pursuit speed adaptation changed according to changes in the target amplitude, being about 40°–50°/s at a target amplitude of 40°–80°. The minimum target amplitude needed to induce rhythmic pursuit eye movements markedly increased from 3.7° at 10°/s to 55.0° at 100°/s. The relationship between the gain (the ratio of eye speed to target speed) and the pursuit time suggested that pursuit eye speeds may depend on the pursuit time rather than absolute target speeds and that the gain might become unity even at fast target speeds, provided the critical pursuit time is given.},
author = {Takahashi, Masahiro and Uemura, Takuya and Fujishiro, Takehisa},
doi = {10.1007/BF00453933},
issn = {0302-9530},
journal = {Archives of Oto-Rhino-Laryngology},
keywords = {gaze analysis,smooth pursuit},
mendeley-tags = {gaze analysis,smooth pursuit},
month = oct,
number = {3},
pages = {225--232},
title = {{Quantitative analysis of pursuit eye movements by unidirectional target motion}},
url = {http://link.springer.com/10.1007/BF00453933},
volume = {238},
year = {1983}
}
@article{Tan2006,
abstract = {The proposed method performs the determination of eye blink states by tracking iris and eyelids. Two novelties of this method are the simultaneous exploitation of intensity and edge information for detecting the eye state as well as the record of the patterns of eyelids before closing for tracking the reopened eyes. Experiments show the efficiency of the proposed method.},
author = {Tan, Huachun and Zhang, Yu-Jin},
doi = {10.1016/j.patrec.2005.10.005},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2006/Tan, Zhang/Tan, Zhang - 2006 - Detecting eye blink states by tracking iris and eyelids.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = apr,
number = {6},
pages = {667--675},
title = {{Detecting eye blink states by tracking iris and eyelids}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865505002953 http://linkinghub.elsevier.com/retrieve/pii/S0167865505002953},
volume = {27},
year = {2006}
}
@article{Torricelli2009,
author = {Torricelli, Diego and Goffredo, Michela and Conforto, Silvia and Schmid, Maurizio},
doi = {10.1016/j.patrec.2009.05.014},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2009/Torricelli et al/Torricelli et al. - 2009 - An adaptive blink detector to initialize and update a view-basedremote eye gaze tracking system in a natural.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = sep,
number = {12},
pages = {1144--1150},
title = {{An adaptive blink detector to initialize and update a view-basedremote eye gaze tracking system in a natural scenario}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865509001329 http://linkinghub.elsevier.com/retrieve/pii/S0167865509001329},
volume = {30},
year = {2009}
}
@article{Urruty2007,
abstract = {Eye movements are certainly the most natural and repetitive movement of a human being. The most mundane activity, such as watching television or reading a newspaper, involves this automatic activity which consists of shifting our gaze from one point to another. Identification of the components of eye movements (fixations and saccades) is an essential part in the analysis of visual behavior because these types of movements provide the basic elements used by further investigations of human vision. However, many of the algorithms that detect fixations present a number of problems. In this article, we present a new fixation identification technique that is based on clustering of eye positions, using projections and projection aggregation applied to static pictures. We also present a new method that computes dispersion of eye fixations in videos considering a multiuser environment. To demonstrate the performance and usefulness of our approach we discuss our experimental work with two different applications: on fixed image and video.},
annote = {        From Duplicate 1 (                           Detecting eye fixations by projection clustering                         - Urruty, Thierry; Lew, Stanislas; Ihadaddene, Nacim; Simovici, Dan A. )
                
        From Duplicate 1 (                           Detecting eye fixations by projection clustering                         - Urruty, T; Lew, S )
                
- cited by: 13
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000
        
        
        
        From Duplicate 2 (                           Detecting eye fixations by projection clustering                         - Urruty, Thierry; Lew, Stanislas; Ihadaddene, Nacim; Simovici, Dan A. )
                
- keyword coletado
        
      },
author = {Urruty, Thierry and Lew, Stanislas and Ihadaddene, Nacim and Simovici, Dan A.},
doi = {10.1145/1314303.1314308},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {Eye Tracking,Segmentation,gaze analysis},
mendeley-tags = {Eye Tracking,Segmentation,gaze analysis},
month = dec,
number = {4},
pages = {1--20},
title = {{Detecting eye fixations by projection clustering}},
url = {http://dl.acm.org/citation.cfm?id=1314308 http://portal.acm.org/citation.cfm?doid=1314303.1314308},
volume = {3},
year = {2007}
}
@article{Lans2011,
abstract = {We propose a new fully automated velocity-based algorithm to identify fixations from eye-movement records of both eyes, with individual-specific thresholds. The algorithm is based on robust minimum determinant covariance estimators (MDC) and control chart procedures, and is conceptually simple and computationally attractive. To determine fixations, it uses velocity thresholds based on the natural within-fixation variability of both eyes. It improves over existing approaches by automatically identifying fixation thresholds that are specific to (a) both eyes, (b) x- and y- directions, (c) tasks, and (d) individuals. We applied the proposed Binocular-Individual Threshold (BIT) algorithm to two large datasets collected on eye-trackers with different sampling frequencies, and compute descriptive statistics of fixations for larger samples of individuals across a variety of tasks, including reading, scene viewing, and search on supermarket shelves. Our analysis shows that there are considerable differences in the characteristics of fixations not only between these tasks, but also between individuals.},
annote = {- cited by: 9
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {van der Lans, Ralf and Wedel, Michel and Pieters, Rik},
doi = {10.3758/s13428-010-0031-2},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2011/van der Lans, Wedel, Pieters/van der Lans, Wedel, Pieters - 2011 - Defining eye-fixation sequences across individuals and tasks the Binocular-Individual Threshold (B.pdf:pdf;:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2011/van der Lans, Wedel, Pieters/van der Lans, Wedel, Pieters - 2011 - Defining eye-fixation sequences across individuals and tasks the Binocular-Individual Threshold (.epub:epub},
issn = {1554-3528},
journal = {Behavior research methods},
keywords = {Adolescent,Algorithms,Binocular,Binocular: physiology,Blinking,Data Interpretation,Female,Fixation,Functional Laterality,Functional Laterality: physiology,Humans,Male,Ocular,Ocular: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reading,Saccades,Sensory Thresholds,Sensory Thresholds: physiology,Statistical,Vision,Young Adult,gaze analysis},
mendeley-tags = {gaze analysis},
month = mar,
number = {1},
pages = {239--57},
pmid = {21287116},
title = {{Defining eye-fixation sequences across individuals and tasks: the Binocular-Individual Threshold (BIT) algorithm.}},
url = {http://link.springer.com/article/10.3758/s13428-010-0031-2 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3048294\&tool=pmcentrez\&rendertype=abstract},
volume = {43},
year = {2011}
}
@article{Veneri2011,
abstract = {Eye movement is the simplest and repetitive movement that enables humans to interact with the environment. The common daily activities, such as reading a book or watching television, involve this natural activity, which consists of rapidly shifting our gaze from one region to another. In clinical application, the identification of the main components of eye movement during visual exploration, such as fixations and saccades, is the objective of the analysis of eye movements: however, in patients affected by motor control disorder the identification of fixation is not banal. This work presents a new fixation identification algorithm based on the analysis of variance and covariance: the main idea was to use bivariate statistical analysis to compare variance over x and y to identify fixation. We describe the new algorithm, and we compare it with the common fixations algorithm based on dispersion. To demonstrate the performance of our approach, we tested the algorithm in a group of healthy subjects and patients affected by motor control disorder.},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Veneri, Giacomo and Piu, Pietro and Rosini, Francesca and Federighi, Pamela and Federico, Antonio and Rufa, Alessandra},
doi = {10.1016/j.patrec.2011.06.012},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Pattern Recognition Letters/2011/Veneri et al/Veneri et al. - 2011 - Automatic eye fixations identification based on analysis of variance and covariance.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = oct,
number = {13},
pages = {1588--1593},
title = {{Automatic eye fixations identification based on analysis of variance and covariance}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865511001887 http://linkinghub.elsevier.com/retrieve/pii/S0167865511001887},
volume = {32},
year = {2011}
}
@book{Wedel2008,
abstract = {In the last decade there has been a rapid growth in commercial applications of eye-tracking technology to assess the effectiveness of visual marketing efforts. Eye-movements are tightly coupled with visual attention which makes them eminent indicators of the covert visual attention process. Now a sizable and growing body of literature exists on attention to visual marketing stimuli. Eye-Tracking for Visual Marketing provides: 1. The foundations of visual attention and eye-tracking; 2. A conceptual framework for eyetracking research in marketing; 3. A review of the marketing literature within this conceptual framework. Motivated from its rising importance in marketing practice and its potential for theoretical contribution, Eye-Tracking for Visual Marketing examines the structure of the eye, the visual brain, eye-movements, and methods for recording and analyzing them. Next, it describes the authors' theory and reviews eye-tracking applications in marketing based on this theory. It conclude with an outlook on future theory and method development and recommendations for practice.},
annote = {- cited by: 35
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Wedel, Michel and Pieters, Rik},
doi = {10.1561/9781601981554},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2008/Wedel, Pieters/Wedel, Pieters - 2008 - Eye tracking for visual marketing.pdf:pdf},
isbn = {9781601981547},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {93},
publisher = {Now Publishers Inc},
title = {{Eye tracking for visual marketing}},
url = {http://books.google.com.br/books?hl=pt-BR\&lr=\&id=\_yjIeqbC8fMC\&oi=fnd\&pg=PA1\&dq=identification+fixation+eye\&ots=ohmt0F8jvc\&sig=hAnJXqqRZC0NbTNsBDJxKuMrdrM},
year = {2008}
}
@article{Wu2010,
abstract = {This study is to investigate the fundamental problems of, (1) facial feature detection and localization, especially eye features; and (2) eye dynamics, including tracking and blink detection. We first describe our contribution to eye localization. Following that, we discuss a simultaneous eye tracking and blink detection system. Facial feature detection is solved in a general object detection framework and its performance for eye localization is presented. A binary tree representation based on feature dependency partitions the object feature space in a coarse to fine manner. In each compact feature subspace, independent component analysis (ICA) is used to get the independent sources, whose probability density functions (PDFs) are modeled by Gaussian mixtures. When applying this representation for the task of eye detection, a subwindow is used to scan the entire image and each obtained image patch is examined using Bayesian criteria to determine the presence of an eye subject. After the eyes are automatically located with binary tree-based probability learning, interactive particle filters are used for simultaneously tracking the eyes and detecting the blinks. The particle filters use classification-based observation models, in which the posterior probabilities are evaluated by logistic regressions in tensor subspaces. Extensive experiments are used to evaluate the performance from two aspects, (1) blink detection rate and the accuracy of blink duration in terms of the frame numbers; (2) eye tracking accuracy. We also present an experimental setup for obtaining the benchmark data in tracking accuracy evaluation. The experimental evaluation demonstrates the capability of this approach.},
author = {Wu, Junwen and Trivedi, Mohan M.},
doi = {10.1145/1671962.1671964},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Multimedia Computing, Communications, and Applications/2010/Wu, Trivedi/Wu, Trivedi - 2010 - An eye localization, tracking and blink pattern recognition system.pdf:pdf},
issn = {15516857},
journal = {ACM Transactions on Multimedia Computing, Communications, and Applications},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
month = mar,
number = {2},
pages = {1--23},
title = {{An eye localization, tracking and blink pattern recognition system}},
url = {http://dl.acm.org/citation.cfm?id=1671964 http://portal.acm.org/citation.cfm?doid=1671962.1671964},
volume = {6},
year = {2010}
}
@inproceedings{Zhu2010,
abstract = {In teleoperation, operators usually have to control multiple devices simultaneously, which requires frequent hand switches between different controllers. We designed and implemented two prototypes, one by applying head motion and the other by integrating eye gaze as intrinsic elements of teleoperation for remote camera control in a multi-control setting. We report a user study of a modeled multi-control experiment that compares the performance of head tracking control, eye tracking control and traditional joystick control. The results provide clear evidence that eye tracking control significantly outperforms joystick and head tracking control in both objective measures and subjective measures.},
address = {New York, New York, USA},
annote = {- cited by: 3
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Zhu, Dingyun and Gedeon, Tom and Taylor, Ken},
booktitle = {Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA '10},
doi = {10.1145/1753846.1753963},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 28th of the international conference extended abstracts on Human factors in computing systems - CHI EA '10/2010/Zhu, Gedeon, Taylor/Zhu, Gedeon, Taylor - 2010 - Natural interaction enhanced remote camera control for teleoperation.pdf:pdf},
isbn = {9781605589305},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {3229--3234},
publisher = {ACM Press},
title = {{Natural interaction enhanced remote camera control for teleoperation}},
url = {http://dl.acm.org/citation.cfm?id=1753963 http://portal.acm.org/citation.cfm?doid=1753846.1753963},
year = {2010}
}
@article{Munn2009,
abstract = {Video-based eye trackers produce an output video showing where a subject is looking, the subject's Point-of-Regard (POR), for each frame of a video of the scene. This information can be extremely valuable, but its analysis can be overwhelming. Analysis of eye-tracked data from portable (wearable) eye trackers is especially daunting, as the scene video may be constantly changing, rendering automatic analysis more difficult. A common way to begin analysis of POR data is to group these data into fixations. In a previous article, we compared the fixations identified (i.e., start and end marked) automatically by an algorithm to those identified manually by users (i.e., manual coders). Here, we extend this automatic identification of fixations to tagging each fixation to a Region-of-Interest (ROI). Our fixation tagging algorithm, FixTag, requires the relative 3D positions of the vertices of ROIs and calibration of the scene camera. Fixation tagging is performed by first calculating the camera projection matrices for keyframes of the scene video (captured by the eye tracker) via an iterative structure and motion recovery algorithm. These matrices are then used to project 3D ROI vertices into the keyframes. A POR for each fixation is matched to a point in the closest keyframe, which is then checked against the 2D projected ROI vertices for tagging. Our fixation tags were compared to those produced by three manual coders tagging the automatically identified fixations for two different scenarios. For each scenario, eight ROIs were defined along with the 3D positions of eight calibration points. Therefore, 17 tags were available for each fixation: 8 for ROIs, 8 for calibration points, and 1 for “other.” For the first scenario, a subject was tracked looking through products on four store shelves, resulting in 182 automatically identified fixations. Our automatic tagging algorithm produced tags that matched those produced by at least one manual coder for 181 out of the 182 fixations (99.5\% agreement). For the second scenario, a subject was tracked looking at two posters on adjoining walls of a room. Our algorithm matched at least one manual coder's tag for 169 fixations out of 172 automatically identified (98.3\% agreement).},
annote = {- cited by: 8
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Munn, Susan M. and Pelz, Jeff B.},
doi = {10.1145/1577755.1577759},
file = {:home/acmt/Dropbox/Documentos/Mendeley/ACM Transactions on Applied Perception/2009/Munn, Pelz/Munn, Pelz - 2009 - FixTag An algorithm for identifying and tagging fixations to simplify the analysis of data collected by portable eye.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = aug,
number = {3},
pages = {1--25},
title = {{FixTag: An algorithm for identifying and tagging fixations to simplify the analysis of data collected by portable eye trackers}},
url = {http://dl.acm.org/citation.cfm?id=1577759 http://portal.acm.org/citation.cfm?doid=1577755.1577759},
volume = {6},
year = {2009}
}
@phdthesis{Agustin2010,
abstract = {People with severe motor-skill disabilities are often unable to use standard input devices such as a mouse or a keyboard to control a computer and they are, therefore, in strong need for alternative input devices. Gaze tracking offers them the possibility to use the movements of their eyes to interact with a computer, thereby making them more independent. A big effort has been put toward improving the robustness and accuracy of the technology, and many commercial systems are nowadays available in the market. Despite the great improvements that gaze tracking systems have undergone in the last years, high prices have prevented gaze interaction from becoming mainstream. The use of specialized hardware, such as industrial cameras or infrared light sources, increases the accuracy of the systems, but also the price, which prevents many poten- tial users fromhaving access to the technology. Furthermore, the different components are often required to be placed in specific locations, or are built into the monitor, thus decreasing the flexibility of the setup. Gaze tracking systems built from low-cost and off-the-shelf components have the potential to facilitate access to the technology and bring the prices down. Such systems are oftenmore flexible, as the components can be placed in different locations, but also less robust, due to the lack of control over the hardware setup and the lower quality of the components compared to commercial systems. The work developed for this thesis deals with some of the challenges introduced by the use of low-cost and off-the-shelf components for gaze interaction. The main contributions are: - Development and performance evaluation of the ITU Gaze Tracker, an off-the- shelf gaze tracker that uses an inexpensive webcam or video camera to track the user’s eye. The software is readily available as open source, offering the possibility to try out gaze interaction for a low price and to analyze, improve and extend the software by modifying the source code. - Anovel gaze estimationmethod based on homographicmappings between planes. No knowledge about the hardware configuration is required, allowing for a flex- ible setup where camera and light sources can be placed at any location. -A novel algorithm to detect the type of movement that the eye is performing, i.e. fixation, saccade or smooth pursuit. The algorithm is based on eye velocity and movement pattern, and allows to smooth the signal appropriately for each kind of movement to remove jitter due to noise while maximizing responsiveness.},
author = {Agustin, Javier San},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2010/Agustin/Agustin - 2010 - Off-the-shelf gaze interaction.pdf:pdf},
keywords = {fixation,gaze events,saccade,smooth pursuit},
mendeley-tags = {fixation,gaze events,saccade,smooth pursuit},
pages = {179},
title = {{Off-the-shelf gaze interaction}},
url = {http://forskningsbasen.deff.dk/Share.external?sp=S3eb0b28e-2894-417a-b93b-747cb73c28f7\&sp=Situ},
year = {2010}
}
@unpublished{Chesnet2011,
abstract = {The decomposition of the movement of the eye into different categories is critical to their study. Ac- cording to the algorithm used, some movements may significantly be over or under estimated. The two most important movements (saccade, swift movement and fixation, when the eye remains on the same position to capture information) are well characterized and usually properly identified by most algorithms, however in the context of writing, some other movements cannot be characterized as fixations or saccades. These movements may either be considered as microsaccades or slow movements which are actually close to saccades of fixations respectively but without completely sharing their characteristics. None of the algorithms available for eye movements classification can handle all the four movements. Some of them tend to first identify fixations by the barycenter method while others first identify saccades by the mean of speed. The approach used here is different as movements are first decomposed into elementary move- ments according to the acceleration scheme before they are merged. This new approach allows a better identification of each of the 4 kinds of movements.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000
        
- Dia lido: N\~{a}o lido},
author = {Alamargot, Denis and Caporossi, Gilles and Chesnet, David},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2011/Alamargot, Caporossi, Chesnet/Alamargot, Caporossi, Chesnet - 2011 - An Algorithm for Qualifying Eye Movements During Handwriting.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {12},
title = {{An Algorithm for Qualifying Eye Movements During Handwriting}},
url = {http://www.gerad.ca/fichiers/cahiers/G-2011-41.pdf},
year = {2011}
}
@phdthesis{Bergstrand2008,
abstract = {The movement of a persons eyes is an interesting factor to study in different research areas where attention is important, for example driving. In 2004 the Swedish national road and transport research institute (VTI) introduced Simu- lator III – their third generation of driving simulators. Inside Simulator III a camera based eye tracking system is installed that records the eye movements of the driver. To be useful, the raw data from the eye tracking system needs to be analyzed and concentrated into a number of measures relevant for the research at VTI. This thesis presents methods to analyze the data from the eye tracker and transform it into something more useful. A world coordinate system is setup to connect the eye tracking system with the real world in a consistent way. A set of measures is collected, mainly from ISO and SAE standards, to be used as output from the analysis. Finally an application is developed for performing the analysis. The application reads the data from the eye tracker and the simulator, analyzes the data, and outputs a set of eye movement measures usable for the researchers at VTI.},
author = {Bergstrand, M},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2008/Bergstrand/Bergstrand - 2008 - Automatic analysis of eye tracker data from a driving simulator.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {63},
school = {Link\"{o}pings unversitet},
title = {{Automatic analysis of eye tracker data from a driving simulator}},
url = {http://www.diva-portal.org/smash/record.jsf?pid=diva2:636736},
year = {2008}
}
@article{Camilli2008,
abstract = {In human factors and ergonomics research, the analysis of eye movements has gained popularity as a method for obtaining information concerning the operators cognitive strategies and for drawing inferences about the cognitive state of an individual. For example, recent studies have shown that the distribution of eye fixations is sensitive to variations in mental workload\&\#x2014;dispersed when workload is high, and clustered when workload is low. Spatial statistics algorithms can be used to obtain information about the type of distribution and can be applied over fixations recorded during small epochs of time to assess online changes in the level of mental load experienced by the individuals. In order to ease the computation of the statistical index and to encourage research on the spatial properties of visual scanning, A Simple Tool for Examining Fixations has been developed. The software application implements functions for fixation visualization, management, and analysis, and includes a tool for fixation identification from raw gaze point data. Updated information can be obtained online at www .astef.info, where the installation package is freely downloadable.},
annote = {- cited by: 25
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Camilli, Marco and Nacchia, Roberto and Terenzi, Michela and Nocera, Francesco},
doi = {10.3758/BRM.40.2.373},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Behavior research methods/2008/Camilli et al/Camilli et al. - 2008 - ASTEF A simple tool for examining fixations.pdf:pdf},
issn = {1554-351X},
journal = {Behavior research methods},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = may,
number = {2},
pages = {373--382},
title = {{ASTEF: A simple tool for examining fixations}},
url = {http://link.springer.com/article/10.3758/BRM.40.2.373 http://www.springerlink.com/index/10.3758/BRM.40.2.373},
volume = {40},
year = {2008}
}
@article{Chin2006,
abstract = {This paper outlines the development and initial testing of a new hybrid computer cursor control system based on Eye Gaze Tracking (EGT) and electromyogram (EMG) processing for hands-free control of the computer cursor. The ultimate goal of the system is to provide an efficient computer interaction mechanism for individuals with severe motor disabilities (or specialized operators whose hands are committed to other tasks, such as surgeons, pilots, etc.) The paper emphasizes the enhancements that have been made on different areas of the architecture, with respect to a previous prototype developed by our group, and demonstrates the performance improvement verified for some of the enhancements.},
annote = {- cited by: 6
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Chin, Craig A and Barreto, Armando},
doi = {10.1109/IEMBS.2006.259595},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Conference proceedings ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engine. Conference/2006/Chin, Barreto/Chin, Barreto - 2006 - Enhanced hybrid electromyogramEye Gaze Tracking cursor control system for hands-free computer interaction.pdf:pdf},
issn = {1557-170X},
journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Conference},
keywords = {Algorithms,Computer Peripherals,Data Display,Electromyography,Electromyography: methods,Eye Movement Measurements,Eye Movements,Eye Movements: physiology,Facial Muscles,Facial Muscles: physiology,Fixation,Humans,Ocular,Ocular: physiology,User-Computer Interface,gaze analysis},
mendeley-tags = {gaze analysis},
month = jan,
pages = {2296--9},
pmid = {17946102},
title = {{Enhanced hybrid electromyogram/Eye Gaze Tracking cursor control system for hands-free computer interaction.}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4462251 http://www.ncbi.nlm.nih.gov/pubmed/17946102},
volume = {1},
year = {2006}
}
@article{Diaz2013a,
abstract = {Despite the growing popularity of virtual reality environments, few laboratories are equipped to investigate eye movements within these environments. This primer is intended to reduce the time and effort required to incorporate eye-tracking equipment into a virtual reality environment. We discuss issues related to the initial startup and provide algorithms necessary for basic analysis. Algorithms are provided for the calculation of gaze angle within a virtual world using a monocular eye-tracker in a three-dimensional environment. In addition, we provide algorithms for the calculation of the angular distance between the gaze and a relevant virtual object and for the identification of fixations, saccades, and pursuit eye movements. Finally, we provide tools that temporally synchronize gaze data and the visual stimulus and enable real-time assembly of a video-based record of the experiment using the Quicktime MOV format, available at http://sourceforge.net/p/utdvrlibraries/. This record contains the visual stimulus, the gaze cursor, and associated numerical data and can be used for data exportation, visual inspection, and validation of calculated gaze movements.},
annote = {- cited by: 1
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Diaz, Gabriel and Cooper, Joseph and Kit, Dmitry and Hayhoe, Mary},
doi = {10.1167/13.12.5},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of vision/2013/Diaz et al/Diaz et al. - 2013 - Real-time recording and classification of eye movements in an immersive virtual environment.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {eye movements,gaze,gaze analysis,methods,virtual reality},
mendeley-tags = {gaze analysis},
month = jan,
number = {12},
pages = {1--14},
pmid = {24113087},
title = {{Real-time recording and classification of eye movements in an immersive virtual environment.}},
url = {http://w.journalofvision.org/content/13/12/5.short http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3795427\&tool=pmcentrez\&rendertype=abstract},
volume = {13},
year = {2013}
}
@inproceedings{Eichner,
abstract = {Salvucci \& Goldberg (2000) described dispersion algorithms (I-DT) as a robust way for fixation detection in low-speed-eytrackers. Never the less Shic, Chawarska and Scassellati (2008) found that changing settings for thresholds in the used I-DT altered the relation between independent and dependent variables significantly. Furthermore they concluded that it could be more important to find the relationships between measured variables and threshold settings than finding the “right” settings for thresholds. This work used eye- tracking data from reading and motivational research (N=280; 50 Hz) to find answers to this question. The findings show that dispersion thresholds are not crucial for relationship changes in variables, but temporal thresholds are. The theoretical approach separates physiological from psychological temporal thresholds. Findings indicate that psychological thresholds can be applied to fixation data outside the I-DT parameters to find meaningful relationships.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000
        
Eichner diz que n\~{a}o existe o melhor threshold para os algoritmos de dispers\~{a}o, e que \'{e} mais importante descobrir as rela\c{c}\~{o}es entre os as medi\c{c}\~{o}es e os par\^{a}metros do threshold. Ele descobre que thresholds espaciais n\~{a}o contribuem muito com a varia\c{c}\~{a}o dessa rela\c{c}\~{a}o, todavia os par\^{a}metros temporais contribuem.
        
Lido - 2013-12-10 12:47:00 },
author = {Eichner, M},
booktitle = {EyeTrackBehavior Conference},
file = {:home/acmt/Dropbox/Documentos/Mendeley/EyeTrackBehavior Conference/2011/Eichner/Eichner - 2011 - Do thresholds in dispersion-algorithms matter in applied eye movement studies.pdf:pdf},
keywords = {Eye movements,dispersion algorithm,fixation detection,gaze analysis,reading,threshold},
mendeley-tags = {gaze analysis},
pages = {1--2},
title = {{Do thresholds in dispersion-algorithms matter in applied eye movement studies?}},
url = {http://www.uni-giessen.de/~g61314/eyetracking/EichnerM\_Dispersion\_Algs\_Tobii\_EyeTrackingBehavior2011\_rev1.pdf},
year = {2011}
}
@article{Engbert2003,
abstract = {Fixational eye movements are subdivided into tremor, drift, and microsaccades. All three types of miniature eye movements generate small random displacements of the retinal image when viewing a stationary scene. Here we investigate the modulation of microsaccades by shifts of covert attention in a classical spatial cueing paradigm. First, we replicate the suppression of microsaccades with a minimum rate about 150 ms after cue onset. Second, as a new finding we observe microsaccadic enhancement with a maximum rate about 350 ms after presentation of the cue. Third, we find a modulation of the orientation towards the cue direction. These multiple influences of visual attention on microsaccades accentuate their role for visual information processing. Furthermore, our results suggest that microsaccades can be used to map the orientation of visual attention in psychophysical experiments.},
author = {Engbert, Ralf and Kliegl, Reinhold},
doi = {10.1016/S0042-6989(03)00084-1},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2003/Engbert, Kliegl/Engbert, Kliegl - 2003 - Microsaccades uncover the orientation of covert attention.pdf:pdf},
issn = {00426989},
journal = {Vision Research},
keywords = {covert attention,gaze analysis,microsaccades},
mendeley-tags = {covert attention,gaze analysis,microsaccades},
month = apr,
number = {9},
pages = {1035--1045},
title = {{Microsaccades uncover the orientation of covert attention}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698903000841 http://linkinghub.elsevier.com/retrieve/pii/S0042698903000841},
volume = {43},
year = {2003}
}
@article{Foulsham2008,
abstract = {Saliency map models account for a small but significant amount of the variance in where people fixate, but evaluating these models with natural stimuli has led to mixed results. In the present study, the eye movements of participants were recorded while they viewed color photographs of natural scenes in preparation for a memory test (encoding) and when recognizing them later. These eye movements were then compared to the predictions of a well defined saliency map model (L. Itti \& C. Koch, 2000), in terms of both individual fixation locations and fixation sequences (scanpaths). The saliency model is a significantly better predictor of fixation location than random models that take into account bias toward central fixations, and this is the case at both encoding and recognition. However, similarity between scanpaths made at multiple viewings of the same stimulus suggests that repetitive scanpaths also contribute to where people look. Top-down recapitulation of scanpaths is a key prediction of scanpath theory (D. Noton \& L. Stark, 1971), but it might also be explained by bottom-up guidance. The present data suggest that saliency cannot account for scanpaths and that incorporating these sequences could improve model predictions.},
author = {Foulsham, Tom and Underwood, Geoffrey},
doi = {10.1167/8.2.6},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of vision/2008/Foulsham, Underwood/Foulsham, Underwood - 2008 - What can saliency models predict about eye movements Spatial and sequential aspects of fixations during enc.pdf:pdf},
issn = {1534-7362},
journal = {Journal of vision},
keywords = {Analysis of Variance,Cognition,Cognition: physiology,Eye Movements,Eye Movements: physiology,Eye Tracking,Fixation,Form Perception,Form Perception: physiology,Humans,Ocular,Ocular: physiology,Pattern Recognition,Photic Stimulation,Segmentation,Semantics,Task Performance and Analysis,Visual,Visual: physiology,scanpath,similarity},
mendeley-tags = {Eye Tracking,Segmentation,scanpath,similarity},
month = jan,
number = {2},
pages = {6.1--17},
pmid = {18318632},
title = {{What can saliency models predict about eye movements? Spatial and sequential aspects of fixations during encoding and recognition.}},
url = {http://jov.highwire.org/content/8/2/6.short http://www.ncbi.nlm.nih.gov/pubmed/18318632},
volume = {8},
year = {2008}
}
@incollection{Goldberg2014,
author = {Goldberg, JH and Helfman, JI},
booktitle = {Handbook of Human Centric Visualization},
doi = {10.1007/978-1-4614-7485-2\_13},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Handbook of Human Centric Visualization/2014/Goldberg, Helfman/Goldberg, Helfman - 2014 - Eye Tracking on Visualizations Progressive Extraction of Scanning Strategies.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {337--372},
title = {{Eye Tracking on Visualizations: Progressive Extraction of Scanning Strategies}},
url = {http://link.springer.com/chapter/10.1007/978-1-4614-7485-2\_13},
year = {2014}
}
@inproceedings{Hradis2012,
abstract = {This paper discusses estimation of active speaker in multi-party video-mediated communication from gaze data of one of the participants. In the explored settings, we predict voice activity of participants in one room based on gaze recordings of a single participant in another room. The two rooms were connected by high definition, low delay audio and video links and the participants engaged in different activities ranging from casual discussion to simple problem-solving games. We treat the task as a classification problem. We evaluate several types of features and parameter settings in the context of Support Vector Machine classification framework. The results show that using the proposed approach vocal activity of a speaker can be correctly predicted in 89 \% of the time for which the gaze data are available.},
address = {New York, New York, USA},
author = {Hradis, Michal and Eivazi, Shahram and Bednarik, Roman},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12},
doi = {10.1145/2168556.2168628},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12/2012/Hradis, Eivazi, Bednarik/Hradis, Eivazi, Bednarik - 2012 - Voice activity detection from gaze in video mediated communication.pdf:pdf},
isbn = {9781450312219},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {329},
publisher = {ACM Press},
title = {{Voice activity detection from gaze in video mediated communication}},
url = {http://dl.acm.org/citation.cfm?id=2168628 http://dl.acm.org/citation.cfm?doid=2168556.2168628},
year = {2012}
}
@book{Huang2014,
address = {New York, NY},
doi = {10.1007/978-1-4614-7485-2},
editor = {Huang, Weidong},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unknown/2014/Unknown/Unknown - 2014 - Handbook of Human Centric Visualization.pdf:pdf},
isbn = {978-1-4614-7484-5},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
publisher = {Springer New York},
title = {{Handbook of Human Centric Visualization}},
url = {http://link.springer.com/10.1007/978-1-4614-7485-2},
year = {2014}
}
@article{Jang2013,
abstract = {We propose a novel approach for the identification of human implicit visual search intention based on eye movement patterns and pupillary analysis, in general, as well as pupil size, gradient of pupil size variation, fixation length and fixation count corresponding to areas of interest, and fixation count corresponding to non-areas of interest, in particular. The proposed model identifies human implicit visual search intention as task-free visual browsing or task-oriented visual search. Task-oriented visual search is further identified as task-oriented visual search intent generation, task-oriented visual search intent maintenance, or task-oriented visual search intent disappearance. During a visual search, measurement of the pupillary response is greatly influenced by external factors such the intensity and size of the visual stimulus. To alleviate the effects of external factors, we propose a robust baseline model that can accurately measure the pupillary response. Graphical representation of the measured parameter values shows significant differences among the different intent conditions, which can then be used as features for identification. By using the eye movement patterns and pupillary analysis, we can detect the transitions between different implicit intentions—task-free visual browsing intent to task-oriented visual search intent and task-oriented visual search intent maintenance to task-oriented visual search intent disappearance—using a hierarchical support vector machine. In the proposed model, the hierarchical support vector machine is able to identify the transitions between different intent conditions with greater than 90 \% accuracy.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Jang, Young-Min and Mallipeddi, Rammohan and Lee, Minho},
doi = {10.1007/s11257-013-9142-7},
file = {:home/acmt/Dropbox/Documentos/Mendeley/User Modeling and User-Adapted Interaction/2013/Jang, Mallipeddi, Lee/Jang, Mallipeddi, Lee - 2013 - Identification of human implicit visual search intention based on eye movement and pupillary analysis.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = apr,
title = {{Identification of human implicit visual search intention based on eye movement and pupillary analysis}},
url = {http://link.springer.com/article/10.1007/s11257-013-9142-7 http://link.springer.com/10.1007/s11257-013-9142-7},
year = {2013}
}
@article{Juhola1988,
abstract = {A method based on a recursive digital filter is presented that recognizes minima and maxima of nystagmus. The method does not require user assistance. However, it takes into account the type and changes of input by adapting itself to these. The method has been tested with nystagmus data. If the algorithm is slightly modified, it can detect other eye movements.},
author = {Juhola, M},
doi = {10.1109/10.1398},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on bio-medical engineering/1988/Juhola/Juhola - 1988 - Detection of nystagmus eye movements using a recursive digital filter.pdf:pdf},
issn = {0018-9294},
journal = {IEEE transactions on bio-medical engineering},
keywords = {Algorithms,Computer-Assisted,Electronystagmography,Electronystagmography: methods,Humans,Signal Processing,gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = may,
number = {5},
pages = {389--95},
pmid = {3397089},
title = {{Detection of nystagmus eye movements using a recursive digital filter.}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1398 http://www.ncbi.nlm.nih.gov/pubmed/3397089},
volume = {35},
year = {1988}
}
@article{Juhola2006,
abstract = {Eye movements have been investigated in several areas of medicine and also elsewhere, such as in psychology or even in the development of human-computer interfaces. In the last few years we have designed a technique to stimulate, measure and analyze vestibulo-ocular reflex eye movements. In the otoneurological literature these are seen as a novel and promising means of revealing certain disorders and diseases associated with vertigo. Vestibulo-ocular reflex is stimulated by impulsive head movements. We developed the present pattern recognition technique to detect the stimulus (impulsive head movements) and the vestibulo-ocular reflex (response eye movements) generated from signals and to compute the latency and the gain values between them. Using our technique to calculate these attributes, we obtained clearly different results for a group of 22 dizzy patients than for a group of 30 healthy subjects.},
author = {Juhola, Martti and Aalto, Heikki and Hirvonen, Timo},
doi = {10.1007/s10439-006-9129-1},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Annals of biomedical engineering/2006/Juhola, Aalto, Hirvonen/Juhola, Aalto, Hirvonen - 2006 - A signal analysis technique of vestibulo-ocular reflex stimulated with impulsive head movements.pdf:pdf},
issn = {0090-6964},
journal = {Annals of biomedical engineering},
keywords = {Automated,Automated: methods,Computer-Assisted,Computer-Assisted: instrumentation,Dizziness,Dizziness: diagnosis,Eye Movements,Female,Head Movements,Humans,Male,Pattern Recognition,Reflex,Signal Processing,Vertigo,Vertigo: diagnosis,Vestibulo-Ocular,gaze analysis,nystagmus},
mendeley-tags = {gaze analysis,nystagmus},
month = jul,
number = {7},
pages = {1213--25},
pmid = {16786396},
title = {{A signal analysis technique of vestibulo-ocular reflex stimulated with impulsive head movements.}},
url = {http://link.springer.com/article/10.1007/s10439-006-9129-1 http://www.ncbi.nlm.nih.gov/pubmed/16786396},
volume = {34},
year = {2006}
}
@inproceedings{Kang2011,
abstract = {Human visual attention is an area of research that has a strong effect on the field of human-robot-interaction. It has various applications for human-care robots and service robots. The ability of human visual attention to acquire knowledge on informative objects through interaction with the environment is an important research issue in the field of human-computer interaction and augmented cognition. Such knowledge can be acquired by automatically detecting visually attentive regions using the fixation extracted from eye-tracking data. Therefore, the optimal fixation must be selected from human eye-tracking data to detect the region of interest. In this paper, eye movement tracking was accurately used to capture human eye movements and to characterize the location and extent of a user's interest as an input mechanism to drive the interaction system. Furthermore, both top-down and bottom-up processes of the human visual system were at work in the process of selective attention. The correlation between human eye movement information and the bottom-up saliency map was calculated and compared with the correlation that was calculated by combining the top-down and bottom-up processes. The experiment results showed that the human visual attention system cannot be constructed with the bottom-up process alone and requires the combination of the top-down and bottom-up processes together.},
address = {Karon Beach, Phuket},
author = {Kang, Dooseok and Lee, Sukhan and Lee, Yu-Bu},
booktitle = {2011 IEEE International Conference on Robotics and Biomimetics},
doi = {10.1109/ROBIO.2011.6181594},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2011 IEEE International Conference on Robotics and Biomimetics/2011/Kang, Lee, Lee/Kang, Lee, Lee - 2011 - Human visual attention with context-specific top-down saliency.pdf:pdf},
isbn = {978-1-4577-2138-0},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = dec,
pages = {2055--2060},
publisher = {IEEE},
title = {{Human visual attention with context-specific top-down saliency}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6181594 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6181594},
year = {2011}
}
@article{Karpov,
author = {Karpov, A and Komogortsev, Oleg V},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Behavioral Research Methods/2012/Karpov, Komogortsev/Karpov, Komogortsev - 2012 - Automated Classification and Scoring of Smooth Pursuit Eye Movements in Presence of Fixations and Saccades.pdf:pdf},
journal = {Journal of Behavioral Research Methods},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1--13},
title = {{Automated Classification and Scoring of Smooth Pursuit Eye Movements in Presence of Fixations and Saccades}},
url = {http://cs.txstate.edu/~ok11/papers\_published/TR2011\_11\_23\_SP\_Ka\_Ko.pdf},
year = {2012}
}
@inproceedings{Kinnunen2010,
abstract = {We propose a person authentication system using eye movement signals. In security scenarios, eye-tracking has earlier been used for gaze-based password entry. A few authors have also used physical features of eye movement signals for authentication in a task-dependent scenario with matched training and test samples. We propose and implement a task-independent scenario whereby the training and test samples can be arbitrary. We use short-term eye gaze direction to construct feature vectors which are modeled using Gaussian mixtures. The results suggest that there are personspecific features in the eye movements that can be modeled in a task-independent manner. The range of possible applications extends beyond the security-type of authentication to proactive and user-convenience systems.},
address = {New York, New York, USA},
annote = {- cited by: 13
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Kinnunen, Tomi and Sedlak, Filip and Bednarik, Roman},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743712},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Kinnunen, Sedlak, Bednarik/Kinnunen, Sedlak, Bednarik - 2010 - Towards task-independent person authentication using eye movement signals.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {187},
publisher = {ACM Press},
title = {{Towards task-independent person authentication using eye movement signals}},
url = {http://dl.acm.org/citation.cfm?id=1743712 http://portal.acm.org/citation.cfm?doid=1743666.1743712},
year = {2010}
}
@inproceedings{Kinsman2010,
abstract = {The classification of a large number of images is a familiar problem to the image processing community. It occurs in consumer photography, bioinformatics, biomedical imaging, surveillance, and in the field of mobile eye-tracking studies. During eye-tracking studies, what a person looks at is recorded, and for each frame what the person looked at must then be analyzed and classified. In many cases the data analysis time restricts the scope of the studies. This paper describes the initial use of hierarchical clustering of these images to minimize the time required during analysis. Pre-clustering the images allows the user to classify a large number of images simultaneously. The success of this method is dependent on meeting requirements for human-computer-interactions, which are also discussed.},
address = {Rochester, NY},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Kinsman, Thomas and Bajorski, Peter and Pelz, Jeff B.},
booktitle = {2010 Western New York Image Processing Workshop},
doi = {10.1109/WNYIPW.2010.5649742},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 Western New York Image Processing Workshop/2010/Kinsman, Bajorski, Pelz/Kinsman, Bajorski, Pelz - 2010 - Hierarchical image clustering for analyzing eye tracking videos.pdf:pdf},
isbn = {978-1-4244-9298-5},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = nov,
pages = {58--61},
publisher = {IEEE},
title = {{Hierarchical image clustering for analyzing eye tracking videos}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5649742 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5649742},
year = {2010}
}
@inproceedings{Klingner2010,
abstract = {We propose a new way of analyzing pupil measurements made in conjunction with eye tracking: fixation-aligned pupillary response averaging, in which short windows of continuous pupil measurements are selected based on patterns in eye tracking data, temporally aligned, and averaged together. Such short pupil data epochs can be selected based on fixations on a particular spot or a scan path. The windows of pupil data thus selected are aligned by temporal translation and linear warping to place corresponding parts of the gaze patterns at corresponding times and then averaged together. This approach enables the measurement of quick changes in cognitive load during visual tasks, in which task components occur at unpredictable times but are identifiable via gaze data. We illustrate the method through example analyses of visual search and map reading. We conclude with a discussion of the scope and limitations of this new method.},
address = {New York, New York, USA},
annote = {- cited by: 8
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Klingner, Jeff},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743732},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Klingner/Klingner - 2010 - Fixation-aligned pupillary response averaging.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {275},
publisher = {ACM Press},
title = {{Fixation-aligned pupillary response averaging}},
url = {http://dl.acm.org/citation.cfm?id=1743732 http://portal.acm.org/citation.cfm?doid=1743666.1743732},
year = {2010}
}
@misc{Komogortsev2013a,
author = {Komogortsev, Oleg V},
title = {{Eye movement Classification [Software]}},
url = {http://cs.txstate.edu/~ok11/emd_offline.html},
urldate = {2013-12-14},
year = {2013}
}
@inproceedings{Komogortsev2009,
abstract = {In this paper, we introduce and evaluate a new Instantaneous Saccade (IS) selection scheme for eye gaze driven interfaces where the speed of the target selection is of utmost importance. In the IS selection scheme, target selection occurs at the start (onset) of a saccade requiring only constant amount of time to be completed. The IS performance is compared to the conventional Dwell Time (DT) selection scheme where target selection is triggered when a user fixates on an object for a certain amount of time. The IS method is also compared to the Saccade Offset (SO) selection scheme where target selection occurs at the end of a saccade. All three schemes were evaluated in terms of task completion time and the throughput of input performance in horizontal target selection task by six subjects. Results show that the Instantaneous Saccade selection was 57\% faster than the DT selection to complete a task. In terms of throughput comparison, the throughput of the IS selection is 1.9 times greater than the throughput of DT selection. We hypothesize that Instantaneous Saccade selection will be beneficial in gaming environments that require fast very interaction speeds.},
address = {New York, New York, USA},
author = {Komogortsev, Oleg V and Ryu, Young Sam and Koh, Do Hyong and Gowda, Sandeep M.},
booktitle = {Proceedings of the International Conference on Advances in Computer Enterntainment Technology - ACE '09},
doi = {10.1145/1690388.1690412},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the International Conference on Advances in Computer Enterntainment Technology - ACE '09/2009/Komogortsev et al/Komogortsev et al. - 2009 - Instantaneous saccade driven eye gaze interaction.pdf:pdf},
isbn = {9781605588643},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {140},
publisher = {ACM Press},
title = {{Instantaneous saccade driven eye gaze interaction}},
url = {http://dl.acm.org/citation.cfm?id=1690412 http://portal.acm.org/citation.cfm?doid=1690388.1690412},
year = {2009}
}
@inproceedings{Krassanakis2013,
abstract = {The features processed in a primary stage of vision can be of guid- ance to visual search. The list of preattentive features indicated by psychologi- cal research bare many similarities to the fundamental cartographic design tools (visual and dynamic variables). This paper presents the performance of two ex- perimental studies, which examine the influence of preattentive vision in map reading process. The experimental studies involve both “top-down” and “bot- tom-up” procedures. The methodology of eye tracking is used in the experi- ments.},
address = {Scarborough, UK.},
annote = {- cited by: 2
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Krassanakis, V},
booktitle = {Proceedings of the 1st International Workshop on Eye Tracking for Spatial Research},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 1st International Workshop on Eye Tracking for Spatial Research/2013/Krassanakis/Krassanakis - 2013 - Exploring the map reading process with eye movement analysis.pdf:pdf},
keywords = {Preattentive vision,cartographic experimentation,dynamic variables,eye move-,gaze analysis,ment analysis,visual variables},
mendeley-tags = {gaze analysis},
pages = {2--7},
title = {{Exploring the map reading process with eye movement analysis}},
url = {http://spatialeyetracking.org/wp-content/uploads/2013/10/et4s\_2013\_paper1.pdf},
year = {2013}
}
@inproceedings{Kumar2007,
abstract = {We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences.},
address = {New York, New York, USA},
author = {Kumar, Manu and Paepcke, Andreas and Winograd, Terry},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '07},
doi = {10.1145/1240624.1240692},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '07/2007/Kumar, Paepcke, Winograd/Kumar, Paepcke, Winograd - 2007 - EyePoint practical pointing and selection using gaze and keyboard.pdf:pdf},
isbn = {9781595935939},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {421},
publisher = {ACM Press},
title = {{EyePoint: practical pointing and selection using gaze and keyboard}},
url = {http://dl.acm.org/citation.cfm?id=1240692 http://portal.acm.org/citation.cfm?doid=1240624.1240692},
year = {2007}
}
@phdthesis{Larsson2010,
abstract = {A new method of evaluating eye movement classification algorithms using Precision and Recall is proposed. The method involves recording test subjects looking at known stimuli and then testing various algo- rithms’ ability to classify the eye movements that are anticipated. This method is then used to evaluate the performance of different off-line algorithms. The algorithms I-DT, I-VT and an HMM-based method were tested, as well as eye tracking company Tobii Technology’s algorithms Clear- View and Tobii Fixation Filter. An analysis tool, which is available freely to the public, was developed in order to facilitate the process of developing and evaluating classification algorithms. Precision and Recall gave a clear profile of how accurately different algorithms could identify fixations. The implementations of I-VT and ClearView are essentially the same, and so were the results. The HMM offered no improvements, but should not be dismissed completely. To- bii Fixation Filter performed well due to filtering of the data. Most significantly, I-DT performed better than I-VT for fixation identification, while the reverse was true for extracting accurate sac- cadic information.},
author = {Larsson, G},
booktitle = {nada.kth.se},
file = {:home/acmt/Dropbox/Documentos/Mendeley/nada.kth.se/2010/Larsson/Larsson - 2010 - Evaluation methodology of eye movement classification algorithms.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {56},
school = {Royal Institute of Technology},
title = {{Evaluation methodology of eye movement classification algorithms}},
url = {http://www.nada.kth.se/utbildning/grukth/exjobb/rapportlistor/2010/rapporter10/larsson\_gustav\_10064.pdf},
year = {2010}
}
@phdthesis{Larsson2010a,
abstract = {There are three different movements of the eye that are of main interest to detect and investigate by eye movement researchers; fixations, saccades and smooth pursuits. At the moment only two of them, fixations and saccades, can be de- tected by commercial detection algorithms. There are several different types of eye-trackers, each having its own properties and its own detection algorithm. In the first part of this thesis, filters used in different detection algorithms for com- putation of velocity and acceleration are compared and their impact on the pa- rameters describing the properties of the eye movement are investigated. It was shown that the filter used in the algorithm for detection of the eye movement, will have effects on the properties of the detected eye movements. In the second part of the thesis, a detection algorithm that is able to detect the three types of eye movements, is developed. Three different methods for detection of smooth pursuits are evaluated and the results show that a method using a Rayleigh test performs well in the detection of smooth pursuits.},
author = {Larsson, Linn\'{e}a},
booktitle = {Unpublished master's thesis). Lund University, Lund, \ldots},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Unpublished master's thesis). Lund University, Lund, \ldots/2010/Larsson/Larsson - 2010 - Event detection in eye-tracking data.pdf:pdf},
keywords = {event detection,fixation,saccade,smooth pursuit},
mendeley-tags = {event detection,fixation,saccade,smooth pursuit},
school = {Lund University},
title = {{Event detection in eye-tracking data}},
url = {http://scholar.google.com.br/scholar?q=\%22Event+detection+in+eye-tracking+data\%22\&btnG=\&hl=pt-BR\&as\_sdt=0\%2C5\#0},
year = {2010}
}
@article{Larsson2013,
abstract = {A novel algorithm for detection of saccades and postsaccadic oscillations in the presence of smooth pursuit movements is proposed. The method combines saccade detection in the acceleration domain with specialized on- and offset criteria for saccades and postsaccadic oscillations. The performance of the algorithm is evaluated by comparing the detection results to those of an existing velocity-based adaptive algorithm and a manually annotated database. The results show that there is a good agreement between the events detected by the proposed algorithm and those in the annotated database with Cohen's kappa around 0.8 for both a development and a test database. In conclusion, the proposed algorithm accurately detects saccades and postsaccadic oscillations as well as intervals of disturbances.},
author = {Larsson, Linn\'{e}a and Nystr\"{o}m, Marcus and Stridh, Martin},
doi = {10.1109/TBME.2013.2258918},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE transactions on bio-medical engineering/2013/Larsson, Nystr\"{o}m, Stridh/Larsson, Nystr\"{o}m, Stridh - 2013 - Detection of saccades and postsaccadic oscillations in the presence of smooth pursuit.pdf:pdf},
issn = {1558-2531},
journal = {IEEE transactions on bio-medical engineering},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = sep,
number = {9},
pages = {2484--93},
pmid = {23625350},
title = {{Detection of saccades and postsaccadic oscillations in the presence of smooth pursuit.}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6504734 http://www.ncbi.nlm.nih.gov/pubmed/23625350},
volume = {60},
year = {2013}
}
@inproceedings{Mahapatra2008,
abstract = {The importance of motion in attracting attention is well known. While watching videos, where motion is prevalent, how do we quantify the regions that are motion salient? In this paper, we investigate the role of motion in attention and compare it with the influence of other low-level features like image orientation and intensity. We propose a framework for motion saliency. In particular, we integrate motion vector information with spatial and temporal coherency to generate a motion attention map. The results show that our model achieves good performance in identifying regions that are moving and salient. We also find motion to have greater influence on saliency than other low-level features when watching videos.},
author = {Mahapatra, Dwarikanath and Winkler, Stefan and Yen, Shih-Cheng},
booktitle = {Human Vision and Electronic Imaging},
doi = {10.1117/12.766243},
editor = {Rogowitz, Bernice E. and Pappas, Thrasyvoulos N.},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Human Vision and Electronic Imaging/2008/Mahapatra, Winkler, Yen/Mahapatra, Winkler, Yen - 2008 - Motion saliency outweighs other low-level features while watching videos.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = feb,
pages = {68060P--68060P--10},
title = {{Motion saliency outweighs other low-level features while watching videos}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=810996},
year = {2008}
}
@article{Marple-Horvat1996,
annote = {- keyword coletado},
author = {Marple-Horvat, DE and Gilbey, SL and Hollands, MA},
doi = {10.1016/0165-0270(96)00049-0},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Journal of Neuroscience Methods/1996/Marple-Horvat, Gilbey, Hollands/Marple-Horvat, Gilbey, Hollands - 1996 - A method for automatic identification of saccades from eye movement recordings.pdf:pdf},
issn = {01650270},
journal = {Journal of Neuroscience Methods},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
month = aug,
number = {2},
pages = {191--195},
title = {{A method for automatic identification of saccades from eye movement recordings}},
url = {http://www.sciencedirect.com/science/article/pii/0165027096000490 http://linkinghub.elsevier.com/retrieve/pii/0165027096000490},
volume = {67},
year = {1996}
}
@inproceedings{Matsuda2011,
abstract = {Few previous eye-tracking studies incorporated the psychological notion of chunking, a meaningful cognitive unit of information. In the present work, we constructed fixation sequence lists nesting chunks, using isolated saccades as a delimiter. Chunks were extracted from the time-stamped records of the fixation sequences that were coded according to the 5x5 segments imposed on the display. The overwhelming majority chunks consisted of one or two fixations. Most within-chunk distances were zero or one, while the between-chunk distance was relatively dispersed with the modal distance at one, followed by zero. There was good agreement between the rankings of between- and within-chunk loops among the primary and secondary segments on the total number of loops. We found some indications about the layout effect, possible attributable to the presence of sub-area on the right most segments.},
annote = {- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Matsuda, N and Takeuchi, H},
booktitle = {Proceedings of IADIS-IHCI},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of IADIS-IHCI/2011/Matsuda, Takeuchi/Matsuda, Takeuchi - 2011 - Cognitive Chunks Extracted From Eye-Tracking Records of Web Page Readers, Using Isolated Saccades as a Delimi.pdf:pdf},
keywords = {chunking,eye-tracking,fixations,gaze analysis,loops,saccades},
mendeley-tags = {gaze analysis},
pages = {169--176},
title = {{Cognitive Chunks Extracted From Eye-Tracking Records of Web Page Readers, Using Isolated Saccades as a Delimiter}},
url = {http://infoshako.sk.tsukuba.ac.jp/~mazda/dPapers/IHCI11.pdf},
year = {2011}
}
@article{Mould2011,
abstract = {There is no standard method for classifying eye fixations. Thresholds for speed, acceleration, duration, and stability of point of gaze have each been employed to demarcate data, but they have no commonly accepted values. Here, some general distributional properties of eye movements were used to construct a simple method for classifying fixations, without parametric assumptions or expert judgment. The method was primarily speed-based, but the required optimum speed threshold was derived automatically from individual data for each observer and stimulus with the aid of Tibshirani, Walther, and Hastie's 'gap statistic'. An optimum duration threshold, also derived automatically from individual data, was used to eliminate the effects of instrumental noise. The method was tested on data recorded from a video eye-tracker sampling at 250 frames a second while experimental observers viewed static natural scenes in over 30,000 one-second trials. The resulting classifications were compared with those by three independent expert visual classifiers, with 88-94\% agreement, and also against two existing parametric methods. Robustness to instrumental noise and sampling rate were verified in separate simulations. The method was applied to the recorded data to illustrate the variation of mean fixation duration and saccade amplitude across observers and scenes.},
annote = {        From Duplicate 2 (                   A simple nonparametric method for classifying eye fixations.                 - Mould, Matthew S; Foster, David H; Amano, Kinjiro; Oakley, John P )
                
- cited by: 0
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000
        
      },
author = {Mould, Matthew S MS and Foster, DH David H and Amano, Kinjiro and Oakley, JP John P},
doi = {10.1016/j.visres.2011.12.006},
issn = {1878-5646},
journal = {Vision Research},
keywords = {Adult,Female,Fixation,Humans,Male,Nonparametric,Ocular,Ocular: physiology,Photic Stimulation,Photic Stimulation: methods,Saccades,Saccades: physiology,Sensory Thresholds,Sensory Thresholds: physiology,Statistics,Time Factors,Young Adult,gaze analysis},
mendeley-tags = {gaze analysis},
month = mar,
pages = {18--25},
pmid = {22227608},
title = {{A simple nonparametric method for classifying eye fixations}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698911004214 http://personalpages.manchester.ac.uk/staff/david.foster/Research/My\_PDFs/Mould\_etal\_VR\_12\_MS.pdf http://www.ncbi.nlm.nih.gov/pubmed/22227608},
volume = {57},
year = {2012}
}
@inproceedings{Munn2008,
abstract = {Video-based eye trackers produce an output video showing where a subject is looking, the subject's point-of-regard (POR), for each frame of a video of the scene. Fixation-identification algorithms simplify the long list of POR data into a more manageable set of data, especially for further analysis, by grouping PORs into fixations. Most current fixation-identification algorithms assume that the POR data are defined in static two-dimensional scene images and only use these raw POR data to identify fixations. The applicability of these algorithms to gaze data in dynamic scene videos is largely unexplored. We implemented a simple velocity-based, duration-sensitive fixation-identification algorithm and compared its performance to results obtained by three experienced users manually coding the eye tracking data displayed within the scene video such that these manual coders had knowledge of the scene motion. We performed this comparison for eye tracking data collected during two different tasks involving different types of scene motion. These two tasks included a subject walking around a building for about 100 seconds (Task 1) and a seated subject viewing a computer animation (approximately 90 seconds long, Task 2). It took our manual coders on average 75 minutes (stdev = 28) and 80 minutes (17) to code results from the first and second tasks, respectively. The automatic fixation-identification algorithm, implemented in MATLAB and run on an Apple 2.16 GHz MacBook, produced results in 0.26 seconds for Task 1 and 0.21 seconds for Task 2. For the first task (walking), the average percent difference among the three human manual coders was 9\% (3.5) and the average percent difference between the automatically generated results and the three coders was 11\% (2.0). For the second task (animation), the average percent difference among the three human coders was 4\% (0.75) and the average percent difference between the automatically generated results and the three coders was 5\% (0.9).},
address = {New York, New York, USA},
annote = {- cited by: 14
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Munn, SM Susan M. and Stefano, Leanne and Pelz, Jeff B. JB},
booktitle = {Proceedings of the 5th symposium on Applied perception in graphics and visualization - APGV '08},
doi = {10.1145/1394281.1394287},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 5th symposium on Applied perception in graphics and visualization - APGV '08/2008/Munn, Stefano, Pelz/Munn, Stefano, Pelz - 2008 - Fixation-identification in dynamic scenes Comparing an automated algorithm to manual coding.pdf:pdf},
isbn = {9781595939814},
keywords = {fixation,gaze analysis},
mendeley-tags = {fixation,gaze analysis},
pages = {33},
publisher = {ACM Press},
title = {{Fixation-identification in dynamic scenes: Comparing an automated algorithm to manual coding}},
url = {http://dl.acm.org/citation.cfm?id=1394287 http://portal.acm.org/citation.cfm?doid=1394281.1394287},
year = {2008}
}
@article{Niemenlehto2009,
abstract = {The analysis of eye movements has proven to be valuable in both clinical work and research as well as in other fields besides medicine. The detection of saccadic eye movements and the extraction of related saccade parameters, such as maximum angular velocity, amplitude, and duration, are usually performed during the analysis of electro-oculographic (EOG) signals. This article considers a saccade detection method that is based on the constant false alarm rate technique, in which the detection sensitivity is continuously adjusted on the basis of the observed signal in order to keep the number of false alarms constant. The method is computationally efficient, it can operate autonomously without user intervention, and it is capable of detecting saccades in a sequential fashion. Therefore, the method finds potential use in applications that require automated analysis of electro-oculographic signals. Because of the constant false alarm rate property, the method can also perform in situations where ideal measurement conditions cannot be guaranteed and noise presents a considerable problem.},
author = {Niemenlehto, PH},
doi = {10.1016/j.cmpb.2009.04.011},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Computer methods and programs in biomedicine/2009/Niemenlehto/Niemenlehto - 2009 - Constant false alarm rate detection of saccadic eye movements in electro-oculography.pdf:pdf},
issn = {1872-7565},
journal = {Computer methods and programs in biomedicine},
keywords = {Algorithms,Artifacts,Automated,Automated: methods,Computer-Assisted,Computer-Assisted: methods,Diagnosis,Electrooculography,Electrooculography: methods,Humans,Pattern Recognition,Reproducibility of Results,Saccades,Saccades: physiology,Sensitivity and Specificity,Signal Processing,gaze analysis},
mendeley-tags = {gaze analysis},
month = nov,
number = {2},
pages = {158--71},
pmid = {19482371},
title = {{Constant false alarm rate detection of saccadic eye movements in electro-oculography.}},
url = {http://www.sciencedirect.com/science/article/pii/S0169260709001564 http://www.ncbi.nlm.nih.gov/pubmed/19482371},
volume = {96},
year = {2009}
}
@article{Papadopoulos2013,
abstract = {In this paper, a gaze-based Relevance Feedback (RF) approach to region-based image retrieval is presented. Fundamental idea of the proposed method comprises the iterative estimation of the real-world objects (or their constituent parts) that are of interest to the user and the subsequent exploitation of this information for refining the image retrieval results. Primary novelties of this work are: a) the introduction of a new set of gaze features for realizing user’s relevance assessment prediction at region-level, and b) the design of a time-efficient and effective object-based RF framework for image retrieval. Regarding the interpretation of the gaze signal, a novel set of features is introduced by formalizing the problem under a mathematical perspective, contrary to the exclusive use of explicitly defined features that are in principle derived from the psychology domain. Apart from the temporal attributes, the proposed features also represent the spatial characteristics of the gaze signal, which have not been extensively studied in the literature so far. On the other hand, the developed object-based RF mechanism aims at overcoming the main limitation of region-based RF approaches, i.e. the frequently inaccurate estimation of the regions of interest in the retrieved images. Moreover, the incorporation of a single-camera image processing-based gaze tracker makes the overall system cost efficient and portable. As it is shown by the experimental evaluation, the proposed method outperforms representative global- and region-based explicit RF approaches, using a challenging general-purpose image dataset.},
annote = {- cited by: 0
- kw: identification I-DT eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Papadopoulos, G. and Apostolakis, K. and Daras, P.},
doi = {10.1109/TMM.2013.2291535},
file = {:home/acmt/Dropbox/Documentos/Mendeley/IEEE Transactions on Multimedia/2013/Papadopoulos, Apostolakis, Daras/Papadopoulos, Apostolakis, Daras - 2013 - Gaze-Based Relevance Feedback for Realizing Region-Based Image Retrieval.pdf:pdf},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
keywords = {Relevance feedback,gaze analysis,gaze-tracking,image retrieval},
mendeley-tags = {gaze analysis},
number = {99},
pages = {1},
shorttitle = {Multimedia, IEEE Transactions on},
title = {{Gaze-Based Relevance Feedback for Realizing Region-Based Image Retrieval}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6671553\&tag=1},
volume = {PP},
year = {2013}
}
@article{Phillips2013,
abstract = {PURPOSE: To develop an eye-tracking method applicable to three-dimensional (3D) images, where the abnormality is both moving and changing in size. MATERIALS AND METHODS: Research ethics committee approval was granted to record eye-tracking data from six inexperienced readers who inspected eight short (<30 seconds) endoluminal fly-through videos extracted from computed tomographic (CT) colonography examinations. Cases included true-positive and false-positive polyp detections from a previous study (polyp diameters, 5-25 mm). Eye tracking was performed with a desk-mounted tracker, and readers indicated when they saw a polyp with a mouse click. The polyp location on each video frame was quantified subsequently by using a circular mask. Gaze data related to each video frame were calculated relative to the visible polyp boundary and used to identify eye movements that pursue a polyp target as it changes size and position during fly-through. Gaze data were then related to positive polyp detections by readers. RESULTS: Tracking eye gaze on moving 3D images was technically feasible. Gaze was successfully classified by using pursuit analysis, and pursuit-based gaze metrics were able to help discriminate different reader search behaviors and methods of allocating visual attention during polyp identification. Of a total of 16 perceptual errors, 15 were recognition errors. There was only one visual search error. The largest polyp (25 mm) was seen but not recognized by five of six readers. CONCLUSION: Tracking a reader's gaze during endoluminal interpretation of 3D data sets is technically feasible and can be described with pursuit-based metrics. Perceptual errors can be classified into visual search errors and recognition errors. Recognition errors are more frequent in inexperienced readers.},
author = {Phillips, Peter and Boone, Darren and Mallett, Susan and Taylor, Stuart A and Altman, Douglas G and Manning, David and Gale, Alastair and Halligan, Steve},
doi = {10.1148/radiol.12120062},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Radiology/2013/Phillips et al/Phillips et al. - 2013 - Method for tracking eye gaze during interpretation of endoluminal 3D CT colonography technical description and.pdf:pdf},
issn = {1527-1315},
journal = {Radiology},
keywords = {Clinical Competence,Colonic Polyps,Colonic Polyps: radiography,Colonography,Computed Tomographic,Computer-Assisted,Diagnostic Errors,Eye Movements,Humans,Imaging,Radiographic Image Interpretation,Three-Dimensional,gaze analysis},
mendeley-tags = {gaze analysis},
month = jun,
number = {3},
pages = {924--31},
pmid = {23382289},
title = {{Method for tracking eye gaze during interpretation of endoluminal 3D CT colonography: technical description and proposed metrics for analysis.}},
url = {http://radiology.rsna.org/content/267/3/924.short http://www.ncbi.nlm.nih.gov/pubmed/23382289},
volume = {267},
year = {2013}
}
@article{Poynter2013,
abstract = {The purpose of this study was to examine individual differences in eye-movement behavior. Six metrics (Fixation Rate, Duration, and Size; Saccade Amplitude; Micro-Saccade Rate and Amplitude) were used to measure individuals' eye-movement behavior profiles (EmBP). We replicate previous research (Andrews \& Coppola, 1999; Castelhano \& Henderson, 2008) by finding consistent individual differences in fixation duration and saccade amplitude across tasks, and present new findings of stable idiosyncrasies in measures of fixational eye-movement (Fixation Size, Micro-Saccade Rate and Amplitude). Moreover, we observed consistent inter-metric correlations across tasks (e.g., individuals that exhibited relatively high Fixation Rates also presented relative low Micro-Saccade Rates and relatively high Micro-Saccade Amplitudes). Factor Analysis linked the six EmBP metrics together with a single factor, which we speculate might be related to the operational effectiveness of the attentional system, given that individual factor scores were correlated with scores on a self-report measure of attentional function. Normal subjects with relatively high scores on this attention-deficit measure exhibited relatively frequent fixations of short duration and large spatial extent, and relatively infrequent micro-saccades of large amplitude. This EmBP is similar to a general pattern of eye-movement behavior observed with ADHD individuals - difficulty controlling eye movements, maintaining fixation, and inhibiting intrusive saccades. Results of this study indicate that normal individuals exhibit idiosyncratic EmBPs that are quite stable across tasks and are related to attentional ability.},
author = {Poynter, William and Barber, Megan and Inman, Jason and Wiggins, Coral},
doi = {10.1016/j.visres.2013.07.002},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Vision Research/2013/Poynter et al/Poynter et al. - 2013 - Individuals exhibit idiosyncratic eye-movement behavior profiles across tasks.pdf:pdf},
issn = {1878-5646},
journal = {Vision Research},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
month = aug,
pages = {32--8},
pmid = {23867568},
title = {{Individuals exhibit idiosyncratic eye-movement behavior profiles across tasks.}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698913001685 http://www.ncbi.nlm.nih.gov/pubmed/23867568},
volume = {89},
year = {2013}
}
@inproceedings{Ryan2010,
abstract = {Analysis of recordings made by a wearable eye tracker is complicated by video stream synchronization, pupil coordinate mapping, eye movement analysis, and tracking of dynamic Areas Of Interest (AOIs) within the scene. In this paper a semi-automatic system is developed to help automate these processes. Synchronization is accomplished via side by side video playback control. A deformable eye template and calibration dot marker allow reliable initialization via simple drag and drop as well as a user-friendly way to correct the algorithm when it fails. Specifically, drift may be corrected by nudging the detected pupil center to the appropriate coordinates. In a case study, the impact of surrogate nature views on physiological health and perceived well-being is examined via analysis of gaze over images of nature. A match-moving methodology was developed to track AOIs for this particular application but is applicable toward similar future studies.},
address = {New York, New York, USA},
annote = {- cited by: 7
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Ryan, Wayne J. and Duchowski, Andrew T. and Vincent, Ellen A. and Battisto, Dina},
booktitle = {Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10},
doi = {10.1145/1743666.1743722},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2010 Symposium on Eye-Tracking Research \& Applications - ETRA '10/2010/Ryan et al/Ryan et al. - 2010 - Match-moving for area-based analysis of eye movements in natural tasks.pdf:pdf},
isbn = {9781605589947},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {235},
publisher = {ACM Press},
title = {{Match-moving for area-based analysis of eye movements in natural tasks}},
url = {http://dl.acm.org/citation.cfm?id=1743722 http://portal.acm.org/citation.cfm?doid=1743666.1743722},
year = {2010}
}
@inproceedings{Santella2004,
abstract = {Characterizing the location and extent of a viewer's interest, in terms of eye movement recordings, informs a range of investigations in image and scene viewing. We present an automatic data-driven method for accomplishing this, which clusters visual point-of-regard (POR) measurements into gazes and regions-of-interest using the mean shift procedure. Clusters produced using this method form a structured representation of viewer interest, and at the same time are replicable and not heavily influenced by noise or outliers. Thus, they are useful in answering fine-grained questions about where and how a viewer examined an image.},
address = {New York, New York, USA},
author = {Santella, Anthony and DeCarlo, Doug},
booktitle = {Proceedings of the Eye tracking research \& applications symposium on Eye tracking research \& applications - ETRA'2004},
doi = {10.1145/968363.968368},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Eye tracking research \& applications symposium on Eye tracking research \& applications - ETRA'2004/2004/Santella, DeCarlo/Santella, DeCarlo - 2004 - Robust clustering of eye movement recordings for quantification of visual interest.pdf:pdf},
isbn = {1581138253},
keywords = {eye movement,gaze analysis},
mendeley-tags = {eye movement,gaze analysis},
pages = {27--34},
publisher = {ACM Press},
title = {{Robust clustering of eye movement recordings for quantification of visual interest}},
url = {http://dl.acm.org/citation.cfm?id=968368 http://portal.acm.org/citation.cfm?doid=968363.968368},
year = {2004}
}
@article{Sauter1991,
abstract = {A simple but efficient algorithm has been developed for computer analysis of eye tracking movements. The program separates smooth pursuit and saccadic eye movements. Separation of the two components is achieved using a twostep process of saccade detection. First, an AR model of the velocity of the smooth component is identified and used to determine a Kalman filter. Secondly the innovation sequence generated by this filter allows saccade detection. The precise beginning and end of each saccade are found using a Hinkley algorithm. Examples are given of analysis procedure for eye tracking of a random moving target. The method proved to be highly reliable and could be easily extended to other eye movements such as nystagmus.},
author = {Sauter, D and Martin, B. J. and Renzo, N. and Vomscheid, C.},
doi = {10.1007/BF02446297},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Medical \& Biological Engineering \& Computing/1991/Sauter et al/Sauter et al. - 1991 - Analysis of eye tracking movements using innovations generated by a Kalman filter.pdf:pdf},
issn = {0140-0118},
journal = {Medical \& Biological Engineering \& Computing},
keywords = {gaze analysis,saccade,smooth pursuit},
mendeley-tags = {gaze analysis,saccade,smooth pursuit},
month = jan,
number = {1},
pages = {63--69},
title = {{Analysis of eye tracking movements using innovations generated by a Kalman filter}},
url = {http://link.springer.com/article/10.1007/BF02446297 http://link.springer.com/10.1007/BF02446297},
volume = {29},
year = {1991}
}
@inproceedings{Shic2008a,
abstract = {The analysis of eye-tracking data hinges on the ability of automated algorithms to separate rapid saccadic eye movements from stable eye fixations. However, though it has long been known that changing the parameters of fixationidentification algorithms can lead to very different qualitative impressions, less is known about how algorithmic parameters interact with quantitative eye-tracking measures. In this study we show that by manipulating aspects of fixation identification, we can completely reverse the patterns of observed results for mean fixation duration, a measure traditionally associated with cognitive load. However, by linearly mapping mean fixation duration over its parameter space, we obtain a new formulation which addresses many of the deficits of the standard analysis. We use our methods to analyze the gaze patterns of toddlers with autism spectrum disorder and control populations and discuss the observed differences in terms of the physical and cognitive ramifications of our methodology.},
annote = {- cited by: 9
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Shic, F and Chawarska, K and Scassellati, B},
booktitle = {30th Annual Meeting of the Cognitive Science Society},
doi = {10.1.1.145.8123},
file = {:home/acmt/Dropbox/Documentos/Mendeley/30th Annual Meeting of the Cognitive Science Society/2008/Shic, Chawarska, Scassellati/Shic, Chawarska, Scassellati - 2008 - The amorphous fixation measure revisited with applications to autism.pdf:pdf},
keywords = {gaze analysis},
mendeley-tags = {gaze analysis},
pages = {1--6},
title = {{The amorphous fixation measure revisited: with applications to autism}},
url = {http://scazlab.yale.edu/sites/default/files/files/Shic-CogSci-2008.pdf http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.145.8123},
year = {2008}
}
@inproceedings{Shic2008,
abstract = {In this paper we evaluate several of the most popular algorithms for segmenting fixations from saccades by testing these algorithms on the scanning patterns of toddlers. We show that by changing the parameters of these algorithms we change the reported fixation durations in a systematic fashion. However, we also show how choices in analysis can lead to very different interpretations of the same eye-tracking data. Methods for reconciling the disparate results of different algorithms as well as suggestions for the use of fixation identification algorithms in analysis, are presented.},
address = {New York, New York, USA},
annote = {- keyword coletado
- cited by: 28
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000

        
Resumo: Shic explora diferentes algoritmos de identifica\c{c}\~{a}o de fixa\c{c}\~{o}es mostrando que suas interpreta\c{c}\~{o}es podem ser diferentes, mesmo trabalhando com os mesmos dados coletados.
Ele analisa os seguintes algoritmos baseados em dispers\~{a}o:
- Dispers\~{a}o de Dist\^{a}ncia: a dist\^{a}ncia entre dois pontos quaisquer na fixa\c{c}\~{a}o n\~{a}o pode superar um limiar. \'{E} executado em O(n²)
- Centr\'{o}ide: os pontos de uma fixa\c{c}\~{a}o n\~{a}o podem ser mais distantes do que um limiar para sua centr\'{o}ide. Pode construir uma vers\~{a}o em tempo real, computando apenas os novos pontos.
- Posi\c{c}\~{a}o-Vari\^{a}ncia: modela o grupo de pontos como uma distribui\c{c}\~{a}o gaussiana, e n\~{a}o podem ultrapassar um desvio padr\~{a}o de dist\^{a}ncia.
- I-DT de Salvucci: a soma da m\'{a}xima dist\^{a}ncia horizontal com a m\'{a}xima dist\^{a}ncia vertical deve ser menor que um limiar.

        
Ele viu que o tempo de fixa\c{c}\~{a}o m\'{e}dio segue um comportamento linear para valores que correspondem aos limites fisiol\'{o}gicos da vis\~{a}o foveal (desvio padr\~{a}o da dispers\~{a}o at\'{e} 1̣° e tempo m\'{\i}nimo de fixa\c{c}\~{a}o at\'{e} 200ms), mesmo que o n\'{u}mero de fixa\c{c}\~{o}es e o total de tempo gasto nas fixa\c{c}\~{o}es forem n\~{a}o lineares.},
author = {Shic, Frederick and Scassellati, Brian and Chawarska, Katarzyna},
booktitle = {Proceedings of the 2008 symposium on Eye tracking research \& applications - ETRA '08},
doi = {10.1145/1344471.1344500},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the 2008 symposium on Eye tracking research \& applications - ETRA '08/2008/Shic, Scassellati, Chawarska/Shic, Scassellati, Chawarska - 2008 - The incomplete fixation measure.pdf:pdf},
isbn = {9781595939821},
keywords = {Eye Tracking,Segmentation},
mendeley-tags = {Eye Tracking,Segmentation},
pages = {111},
publisher = {ACM Press},
title = {{The incomplete fixation measure}},
url = {http://dl.acm.org/citation.cfm?id=1344500 http://portal.acm.org/citation.cfm?doid=1344471.1344500},
year = {2008}
}
@inproceedings{Spakov2012,
abstract = {We compared various real-time filters designed to denoise eye movements from low-sampling devices. Most of the filters found in literature were implemented and tested on data gathered in a previous study. An improvement was proposed for one of the filters. Parameters of each filter were adjusted to ensure their best performance. Four estimation parameters were proposed as criteria for comparison. The output from the filters was compared against two idealized signals (the signals denoised offline). The study revealed that FIR filters with triangular or Gaussian kernel (weighting) functions and parameters dependent on signal state show the best performance.},
address = {New York, New York, USA},
author = {\v{S}pakov, Oleg},
booktitle = {Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12},
doi = {10.1145/2168556.2168616},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Proceedings of the Symposium on Eye Tracking Research and Applications - ETRA '12/2012/\v{S}pakov/\v{S}pakov - 2012 - Comparison of eye movement filters used in HCI(2).pdf:pdf},
isbn = {9781450312219},
keywords = {Gaze analysis},
mendeley-tags = {Gaze analysis},
pages = {281},
publisher = {ACM Press},
title = {{Comparison of eye movement filters used in HCI}},
url = {http://dl.acm.org/citation.cfm?id=2168616 http://dl.acm.org/citation.cfm?doid=2168556.2168616},
year = {2012}
}
@article{Spakov2007,
abstract = {Eye tracking devices generate enormous amount of data, which requires a well-balanced approach to selective visualization of the data. This approach involves employing some data clustering algorithm. Most of the tradi- tional algorithms, however, are too slow as well as inadequately deterministic to be applied to eye gaze data. This paper describes our software implementation of two modifications of the clustering algorithm suitable for visualization of eye gaze data. Such a visualization greatly facilitates data analysis by grouping the individual samples into more meaningful units referred to as gaze fixations.},
annote = {- cited by: 3
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {\v{S}pakov, Oleg and Miniotas, D},
file = {:home/acmt/Dropbox/Documentos/Mendeley/Information Technology and Control/2007/\v{S}pakov, Miniotas/\v{S}pakov, Miniotas - 2007 - Application of clustering algorithms in eye gaze visualizations.pdf:pdf},
journal = {Information Technology and Control},
keywords = {clustering algorithms,data clusters,eye tracking,gaze analysis,information visualization,pie charts.},
mendeley-tags = {gaze analysis},
number = {2},
pages = {213--216},
title = {{Application of clustering algorithms in eye gaze visualizations}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.116.1091\&rep=rep1\&type=pdf},
volume = {36},
year = {2007}
}
@inproceedings{Veneri2010,
abstract = {Eye movement is the most simple and repetitive movement that enable humans to interact with the environment. The common daily activities, such as watching television or reading a book, involve this natural activity which consists of rapidly shifting our gaze from one region to another. The identification of the main components of eye movement during visual exploration such as fixations and saccades, is the objective of the analysis of eye movements in various contexts ranging from basic neuro sciences and visual sciences to virtual reality interactions and robotics. However, many of the algorithms that detect fixations present a number of problems. In this article, we present a new fixation identification algorithm based on the analysis of variance and F-test. We present the new algorithm and we compare it with the common fixations algorithm based on dispersion. To demonstrate the performance of our approach we tested the algorithm in a group of healthy subjects.},
annote = {- cited by: 5
- kw: identification fixation eye
- engine: Google Scholar
- crossref: inversed Salvucci2000},
author = {Veneri, Giacomo and Piu, Pietro and Federighi, Pamela and Rosini, Francesca and Federico, Antonio and Rufa, Alessandra},
booktitle = {2010 2nd International Workshop on Cognitive Information Processing},
doi = {10.1109/CIP.2010.5604221},
file = {:home/acmt/Dropbox/Documentos/Mendeley/2010 2nd International Workshop on Cognitive Information Processing/2010/Veneri et al/Veneri et al. - 2010 - Eye fixations identification based on statistical analysis - Case study.pdf:pdf},
isbn = {978-1-4244-6459-3},
keywords = {Eye Tracking,F-test,Segmentation,analysis of variance,eye fixations identification,eye movement},
mendeley-tags = {Eye Tracking,Segmentation},
month = jun,
pages = {446--451},
publisher = {IEEE},
title = {{Eye fixations identification based on statistical analysis - Case study}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5604221 http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5604221},
year = {2010}
}
@article{Junwen2008,
abstract = {We present a system that simultaneously tracks eyes and detects eye blinks. Two interactive particle filters are used for this purpose, one for the closed eyes and the other one for the open eyes. Each particle filter is used to track the eye locations as well as the scales of the eye subjects. The set of particles that gives higher confidence is defined as the primary set and the other one is defined as the secondary set. The eye location is estimated by the primary particle filter, and whether the eye status is open or closed is also decided by the label of the primary particle filter. When a new frame comes, the secondary particle filter is reinitialized according to the estimates from the primary particle filter. We use autoregression models for describing the state transition and a classification-based model for measuring the observation. Tensor subspace analysis is used for feature extraction which is followed by a logistic regression model to give the posterior estimation. The performance is carefully evaluated from two aspects: the blink detection rate and the tracking accuracy. The blink detection rate is evaluated using videos from varying scenarios, and the tracking accuracy is given by comparing with the benchmark data obtained using the Vicon motion capturing system. The setup for obtaining benchmark data for tracking accuracy evaluation is presented and experimental results are shown. Extensive experimental evaluations validate the capability of the algorithm.},
author = {Wu, Junwen and Trivedi, Mohan M},
doi = {10.1155/2008/823695},
file = {:home/acmt/Dropbox/Documentos/Mendeley/EURASIP Journal on Advances in Signal Processing/2008/Wu, Trivedi/Wu, Trivedi - 2008 - Simultaneous Eye Tracking and Blink Detection with Interactive Particle Filters.pdf:pdf},
issn = {1687-6180},
journal = {EURASIP Journal on Advances in Signal Processing},
keywords = {blink,gaze analysis},
mendeley-tags = {blink,gaze analysis},
number = {1},
pages = {823695},
title = {{Simultaneous Eye Tracking and Blink Detection with Interactive Particle Filters}},
url = {http://scholar.google.com.br/scholar?start=10\&q=morris+detection+blink+2002\&hl=pt-BR\&as\_sdt=0,5\#5 http://asp.eurasipjournals.com/content/2008/1/823695},
volume = {2008},
year = {2008}
}
